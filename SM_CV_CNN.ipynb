{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SM-CV-CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-oDlnRCigjQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D,Conv1D\n",
        "from keras.layers import MaxPooling1D,MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3moH4lRljwVR",
        "outputId": "299f86ec-46a7-496c-c87b-2cd2a30ee549"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/gdrive/MyDrive/Risk Prediction/Dataset/SMOTEdata.csv',index_col=[0])"
      ],
      "metadata": {
        "id": "tt2xAR4NjjlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "id": "SPyHvnbDj51Z",
        "outputId": "f9d7f5b1-cb4c-41a7-b583-5d297ca91e28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Derivation cohort  LOS_Y  LOS  Severity  Black  White  Asian  Latino  \\\n",
              "7121                  1      1    4         7      1      0      0       0   \n",
              "7122                  0      1   19         2      0      0      0       0   \n",
              "7123                  1      1    9         7      0      0      0       0   \n",
              "7124                  1      1   10         5      0      0      0       0   \n",
              "7125                  0      1   21         3      0      0      0       0   \n",
              "\n",
              "      MI       PVD  ...  CrctProtein  C-Reactive Prot > 10  ProCalCYes  \\\n",
              "7121   0 -0.372374  ...     0.190243                     0           0   \n",
              "7122   0 -0.372374  ...    -0.331234                     0           1   \n",
              "7123   0 -0.372374  ...     1.664204                     1           1   \n",
              "7124   0 -0.372374  ...    -0.661883                     0           0   \n",
              "7125   0 -0.372374  ...     0.064132                     1           1   \n",
              "\n",
              "      Procalcitonin  Procalciton > 0.1  TropYes  Troponin  Troponin > 0.1  \\\n",
              "7121      -0.312628                  0        0 -0.076655               0   \n",
              "7122      -0.282900                  1        1 -0.134453               0   \n",
              "7123       1.010807                  1        0  0.114923               0   \n",
              "7124      -0.088986                  0        1 -0.175698               0   \n",
              "7125      -0.297764                  0        1 -0.165987               0   \n",
              "\n",
              "      Death  Severity_class  \n",
              "7121      1               2  \n",
              "7122      1               0  \n",
              "7123      1               2  \n",
              "7124      1               1  \n",
              "7125      1               1  \n",
              "\n",
              "[5 rows x 85 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-56853d97-10c6-49f8-bc5e-ce99b09a949c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Derivation cohort</th>\n",
              "      <th>LOS_Y</th>\n",
              "      <th>LOS</th>\n",
              "      <th>Severity</th>\n",
              "      <th>Black</th>\n",
              "      <th>White</th>\n",
              "      <th>Asian</th>\n",
              "      <th>Latino</th>\n",
              "      <th>MI</th>\n",
              "      <th>PVD</th>\n",
              "      <th>...</th>\n",
              "      <th>CrctProtein</th>\n",
              "      <th>C-Reactive Prot &gt; 10</th>\n",
              "      <th>ProCalCYes</th>\n",
              "      <th>Procalcitonin</th>\n",
              "      <th>Procalciton &gt; 0.1</th>\n",
              "      <th>TropYes</th>\n",
              "      <th>Troponin</th>\n",
              "      <th>Troponin &gt; 0.1</th>\n",
              "      <th>Death</th>\n",
              "      <th>Severity_class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7121</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.372374</td>\n",
              "      <td>...</td>\n",
              "      <td>0.190243</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.312628</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.076655</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7122</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.372374</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.331234</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.282900</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.134453</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7123</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.372374</td>\n",
              "      <td>...</td>\n",
              "      <td>1.664204</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.010807</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.114923</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7124</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.372374</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.661883</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.088986</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.175698</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7125</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.372374</td>\n",
              "      <td>...</td>\n",
              "      <td>0.064132</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.297764</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.165987</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 85 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-56853d97-10c6-49f8-bc5e-ce99b09a949c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-56853d97-10c6-49f8-bc5e-ce99b09a949c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-56853d97-10c6-49f8-bc5e-ce99b09a949c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "req_features=['LOS_Y', 'LOS', 'Severity',\n",
        "       'All CNS', 'Pure CNS', 'Age.1', 'AgeScore', 'O2 Sat < 94', 'MAP < 70', 'Ddimer', 'D-Dimer > 3', 'PltsScore', 'INRYes', 'INR', 'INR > 1.2', 'BUN',\n",
        "       'BUN > 30', 'Creatinine', 'CrtnScore',\n",
        "       'Sodium < 139 or > 154', 'AST', 'AST > 40', 'WBC', 'WBC <1.8 or > 4.8',\n",
        "       'Lymphocytes < 1', 'IL6 > 150',\n",
        "       'Ferritin', 'Ferritin > 300', 'CrctProtein',\n",
        "       'C-Reactive Prot > 10', 'Procalcitonin',\n",
        "       'Procalciton > 0.1', 'TropYes', 'Troponin', 'Troponin > 0.1']"
      ],
      "metadata": {
        "id": "CF8S0dCqi7vy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=df[req_features]"
      ],
      "metadata": {
        "id": "oc3odoy1jD3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59_tLC-LO02J",
        "outputId": "e82ac727-3e33-40d4-c942-8fb58a628bab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7126, 35)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y=df['Death']"
      ],
      "metadata": {
        "id": "gJacRiiIl4qj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmX6rKx8l6Aa",
        "outputId": "ac731a0a-ce7c-4d03-d7c8-bb32050fa022"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7126,)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv1D(filters=256, kernel_size=3, strides=1, activation='relu', input_shape=(35,1)))\n",
        "model.add(MaxPooling1D(pool_size=2 ,strides=1))\n",
        "#model.add(Conv1D(filters=256, kernel_size=3, strides=1, activation='relu'))\n",
        "#model.add(Conv1D(filters=512, kernel_size=3, strides=1, activation='relu'))\n",
        "model.add(Conv1D(filters=256, kernel_size=3, strides=1, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2 ,strides=1))\n",
        "model.add(Conv1D(filters=256, kernel_size=3, strides=1, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2 ,strides=1))\n",
        "#model.add(Conv1D(filters=256, kernel_size=3, strides=1, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2 ,strides=1))\n",
        "#model.add(Reshape((64,32,3), input_shape=(24,256)))\n",
        "#model.add(Reshape((11,340,3), input_shape=(11,4,256)))\n",
        "#model.add(VGG19(include_top=False,weights=\"imagenet\",input_shape=(64,32,3)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etjyb0Zkl_u6",
        "outputId": "5760a9aa-3481-401e-d0a5-e6cf496e5860"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 33, 256)           1024      \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 32, 256)          0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 30, 256)           196864    \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 29, 256)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 27, 256)           196864    \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPooling  (None, 26, 256)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " max_pooling1d_3 (MaxPooling  (None, 25, 256)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 6400)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                409664    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 806,529\n",
            "Trainable params: 806,529\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.optimizers import SGD, Adam, Adamax, Adadelta\n",
        "import sklearn\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "XLnEQodFmC7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt=Adam(learning_rate= 0.0001)  \n",
        "METRICS = [\n",
        "      keras.metrics.TruePositives(name='tp'),\n",
        "      keras.metrics.FalsePositives(name='fp'),\n",
        "      keras.metrics.TrueNegatives(name='tn'),\n",
        "      keras.metrics.FalseNegatives(name='fn'), \n",
        "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      keras.metrics.Precision(name='Precision'),\n",
        "      keras.metrics.Recall(name='Recall'),\n",
        "      keras.metrics.AUC(name='Auc'),\n",
        "      \n",
        "]"
      ],
      "metadata": {
        "id": "tsWb1eO6mEjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer= opt,\n",
        "              metrics='accuracy')"
      ],
      "metadata": {
        "id": "7g2m4ocXmHFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import classification_report\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score, f1_score, recall_score, roc_auc_score, confusion_matrix"
      ],
      "metadata": {
        "id": "kG_9s7AzmKe7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = KFold(n_splits=10, shuffle=False)"
      ],
      "metadata": {
        "id": "BvGetVS_mNJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "j=1           \n",
        "i=1\n",
        "for train_index, test_index in kfold.split(df):\n",
        "    X4 = df.iloc[train_index].loc[:, req_features]\n",
        "    X5 = df.iloc[test_index][req_features]\n",
        "    y4= df.iloc[train_index].loc[:,'Death']\n",
        "    y5 = df.loc[test_index]['Death']\n",
        "\n",
        "    X6= X4.to_numpy('float64')\n",
        "    X7=np.resize(X6,(X4.shape[0],35,1))\n",
        "    X8= X5.to_numpy('float64')\n",
        "    X9=np.resize(X8,(X5.shape[0],35,1))\n",
        "    y6=y4.to_numpy('int')    #train output\n",
        "    y7=y5.to_numpy('int')\n",
        "    train_x = X7\n",
        "    train_y = y6\n",
        "    validation_x = X9\n",
        "    validation_y = y7\n",
        "    history= model.fit(train_x , train_y, epochs=10, batch_size=12,verbose=1) #Training the model\n",
        "    ypre=model.predict(validation_x)\n",
        "    pre_y=np.round(abs(ypre))\n",
        "    print(f\"Accuracy for the fold no. {i} on the test set: {accuracy_score(validation_y, pre_y )}\")\n",
        "    accuracy = accuracy_score(validation_y, pre_y)\n",
        "    print('Accuracy: %f' % accuracy)\n",
        "    matrix = confusion_matrix(validation_y, pre_y)\n",
        "    print(matrix)\n",
        "    i+= 1 \n",
        "    j=j+1 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cikPOrImQyr",
        "outputId": "61beef6f-8dc1-4c70-8153-f7cd2af93854"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "535/535 [==============================] - 15s 5ms/step - loss: 0.6164 - accuracy: 0.6665\n",
            "Epoch 2/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.5473 - accuracy: 0.7226\n",
            "Epoch 3/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.4880 - accuracy: 0.7624\n",
            "Epoch 4/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.4585 - accuracy: 0.7725\n",
            "Epoch 5/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.4406 - accuracy: 0.7906\n",
            "Epoch 6/10\n",
            "535/535 [==============================] - 3s 5ms/step - loss: 0.4252 - accuracy: 0.7987\n",
            "Epoch 7/10\n",
            "535/535 [==============================] - 3s 7ms/step - loss: 0.4085 - accuracy: 0.8051\n",
            "Epoch 8/10\n",
            "535/535 [==============================] - 3s 5ms/step - loss: 0.3971 - accuracy: 0.8152\n",
            "Epoch 9/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.3926 - accuracy: 0.8138\n",
            "Epoch 10/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.3860 - accuracy: 0.8196\n",
            "Accuracy for the fold no. 1 on the test set: 0.7938288920056101\n",
            "Accuracy: 0.793829\n",
            "[[451  67]\n",
            " [ 80 115]]\n",
            "Epoch 1/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.3886 - accuracy: 0.8162\n",
            "Epoch 2/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.3721 - accuracy: 0.8308\n",
            "Epoch 3/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.3701 - accuracy: 0.8282\n",
            "Epoch 4/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.3647 - accuracy: 0.8293\n",
            "Epoch 5/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.3593 - accuracy: 0.8388\n",
            "Epoch 6/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.3509 - accuracy: 0.8388\n",
            "Epoch 7/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.3474 - accuracy: 0.8383\n",
            "Epoch 8/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.3455 - accuracy: 0.8424\n",
            "Epoch 9/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.3360 - accuracy: 0.8500\n",
            "Epoch 10/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.3306 - accuracy: 0.8530\n",
            "Accuracy for the fold no. 2 on the test set: 0.8008415147265077\n",
            "Accuracy: 0.800842\n",
            "[[438  87]\n",
            " [ 55 133]]\n",
            "Epoch 1/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.3338 - accuracy: 0.8500\n",
            "Epoch 2/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.3237 - accuracy: 0.8486\n",
            "Epoch 3/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.3216 - accuracy: 0.8544\n",
            "Epoch 4/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.3158 - accuracy: 0.8516\n",
            "Epoch 5/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.3115 - accuracy: 0.8645\n",
            "Epoch 6/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.3026 - accuracy: 0.8689\n",
            "Epoch 7/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.2948 - accuracy: 0.8696\n",
            "Epoch 8/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.2957 - accuracy: 0.8665\n",
            "Epoch 9/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.2873 - accuracy: 0.8738\n",
            "Epoch 10/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.2823 - accuracy: 0.8751\n",
            "Accuracy for the fold no. 3 on the test set: 0.7727910238429172\n",
            "Accuracy: 0.772791\n",
            "[[418 107]\n",
            " [ 55 133]]\n",
            "Epoch 1/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.2880 - accuracy: 0.8731\n",
            "Epoch 2/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.2824 - accuracy: 0.8743\n",
            "Epoch 3/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.2743 - accuracy: 0.8790\n",
            "Epoch 4/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.2693 - accuracy: 0.8809\n",
            "Epoch 5/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.2610 - accuracy: 0.8869\n",
            "Epoch 6/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.2566 - accuracy: 0.8857\n",
            "Epoch 7/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.2478 - accuracy: 0.8926\n",
            "Epoch 8/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.2465 - accuracy: 0.8960\n",
            "Epoch 9/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.2440 - accuracy: 0.8905\n",
            "Epoch 10/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.2401 - accuracy: 0.8930\n",
            "Accuracy for the fold no. 4 on the test set: 0.8667601683029453\n",
            "Accuracy: 0.866760\n",
            "[[488  44]\n",
            " [ 51 130]]\n",
            "Epoch 1/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.2435 - accuracy: 0.8947\n",
            "Epoch 2/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.2360 - accuracy: 0.8954\n",
            "Epoch 3/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.2312 - accuracy: 0.9019\n",
            "Epoch 4/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.2260 - accuracy: 0.8991\n",
            "Epoch 5/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.2200 - accuracy: 0.9033\n",
            "Epoch 6/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.2164 - accuracy: 0.9053\n",
            "Epoch 7/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.2046 - accuracy: 0.9117\n",
            "Epoch 8/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.2030 - accuracy: 0.9135\n",
            "Epoch 9/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.2035 - accuracy: 0.9142\n",
            "Epoch 10/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.1913 - accuracy: 0.9205\n",
            "Accuracy for the fold no. 5 on the test set: 0.8934081346423562\n",
            "Accuracy: 0.893408\n",
            "[[522  29]\n",
            " [ 47 115]]\n",
            "Epoch 1/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.1862 - accuracy: 0.9197\n",
            "Epoch 2/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.1798 - accuracy: 0.9223\n",
            "Epoch 3/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.1694 - accuracy: 0.9259\n",
            "Epoch 4/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.1694 - accuracy: 0.9284\n",
            "Epoch 5/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.1592 - accuracy: 0.9347\n",
            "Epoch 6/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.1553 - accuracy: 0.9365\n",
            "Epoch 7/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.1570 - accuracy: 0.9365\n",
            "Epoch 8/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.1492 - accuracy: 0.9400\n",
            "Epoch 9/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.1358 - accuracy: 0.9496\n",
            "Epoch 10/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.1421 - accuracy: 0.9409\n",
            "Accuracy for the fold no. 6 on the test set: 0.8288920056100981\n",
            "Accuracy: 0.828892\n",
            "[[475  83]\n",
            " [ 39 116]]\n",
            "Epoch 1/10\n",
            "535/535 [==============================] - 3s 5ms/step - loss: 0.1602 - accuracy: 0.9353\n",
            "Epoch 2/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.1430 - accuracy: 0.9392\n",
            "Epoch 3/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.1415 - accuracy: 0.9426\n",
            "Epoch 4/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.1366 - accuracy: 0.9442\n",
            "Epoch 5/10\n",
            "535/535 [==============================] - 3s 5ms/step - loss: 0.1330 - accuracy: 0.9495\n",
            "Epoch 6/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.1239 - accuracy: 0.9521\n",
            "Epoch 7/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.1219 - accuracy: 0.9501\n",
            "Epoch 8/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.1124 - accuracy: 0.9568\n",
            "Epoch 9/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.1126 - accuracy: 0.9537\n",
            "Epoch 10/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.1057 - accuracy: 0.9595\n",
            "Accuracy for the fold no. 7 on the test set: 0.8932584269662921\n",
            "Accuracy: 0.893258\n",
            "[[314  40]\n",
            " [ 36 322]]\n",
            "Epoch 1/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.1277 - accuracy: 0.9512\n",
            "Epoch 2/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.1214 - accuracy: 0.9542\n",
            "Epoch 3/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.1099 - accuracy: 0.9563\n",
            "Epoch 4/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.1077 - accuracy: 0.9602\n",
            "Epoch 5/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.1080 - accuracy: 0.9590\n",
            "Epoch 6/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.0963 - accuracy: 0.9624\n",
            "Epoch 7/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.1032 - accuracy: 0.9590\n",
            "Epoch 8/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.0995 - accuracy: 0.9620\n",
            "Epoch 9/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.0922 - accuracy: 0.9671\n",
            "Epoch 10/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.0871 - accuracy: 0.9665\n",
            "Accuracy for the fold no. 8 on the test set: 0.9803370786516854\n",
            "Accuracy: 0.980337\n",
            "[[  0   0]\n",
            " [ 14 698]]\n",
            "Epoch 1/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.0845 - accuracy: 0.9688\n",
            "Epoch 2/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.0866 - accuracy: 0.9671\n",
            "Epoch 3/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.0861 - accuracy: 0.9690\n",
            "Epoch 4/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.0749 - accuracy: 0.9726\n",
            "Epoch 5/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.0794 - accuracy: 0.9696\n",
            "Epoch 6/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.0671 - accuracy: 0.9761\n",
            "Epoch 7/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.0706 - accuracy: 0.9738\n",
            "Epoch 8/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.0820 - accuracy: 0.9682\n",
            "Epoch 9/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.0684 - accuracy: 0.9754\n",
            "Epoch 10/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.0615 - accuracy: 0.9783\n",
            "Accuracy for the fold no. 9 on the test set: 0.9803370786516854\n",
            "Accuracy: 0.980337\n",
            "[[  0   0]\n",
            " [ 14 698]]\n",
            "Epoch 1/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.0611 - accuracy: 0.9775\n",
            "Epoch 2/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.0658 - accuracy: 0.9751\n",
            "Epoch 3/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.0691 - accuracy: 0.9766\n",
            "Epoch 4/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.0607 - accuracy: 0.9780\n",
            "Epoch 5/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.0639 - accuracy: 0.9766\n",
            "Epoch 6/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.0603 - accuracy: 0.9777\n",
            "Epoch 7/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.0624 - accuracy: 0.9763\n",
            "Epoch 8/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.0517 - accuracy: 0.9807\n",
            "Epoch 9/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.0580 - accuracy: 0.9782\n",
            "Epoch 10/10\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.0435 - accuracy: 0.9849\n",
            "Accuracy for the fold no. 10 on the test set: 0.9929775280898876\n",
            "Accuracy: 0.992978\n",
            "[[  0   0]\n",
            " [  5 707]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, Y, test_size=0.2, random_state=2)\n",
        "print(X_train1.shape)\n",
        "print(y_train1.shape)\n",
        "print(X_test1.shape)\n",
        "print(y_test1.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tv3bpovPjZ85",
        "outputId": "315b31b0-fab4-495b-91a7-9f04e440650f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5700, 35)\n",
            "(5700,)\n",
            "(1426, 35)\n",
            "(1426,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test2=np.resize(X_test1,(1426,35,1))   #validation data  \n",
        "y_test2=y_test1.to_numpy('int')    #train output\n",
        "validation_x = X_test2\n",
        "validation_y = y_test2\n",
        "ypre=model.predict(validation_x)\n",
        "pre_y=np.where(ypre>0.5, 1, 0)\n",
        "accuracy = accuracy_score(validation_y, pre_y)\n",
        "auc=metrics.roc_auc_score(validation_y, pre_y)\n",
        "print('Accuracy: %f' % accuracy)\n",
        "print('AUC: %f' % auc)\n",
        "print('Classification Report')\n",
        "target_names = ['Recovered', 'Died']\n",
        "print(classification_report(validation_y, pre_y, target_names=target_names))\n",
        "# confusion matrix\n",
        "matrix = confusion_matrix(validation_y, pre_y)\n",
        "print(matrix)\n",
        "ax=plt.subplot()\n",
        "sns.heatmap(matrix,annot=True,ax=ax,cmap='OrRd_r', fmt='g')#annot=True to annotate cells, fmt='g' numbers not scientific form\n",
        "ax.set_xlabel('Predicted labels'); \n",
        "ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix'); \n",
        "ax.xaxis.set_ticklabels(['Died', 'recovered']); \n",
        "ax.yaxis.set_ticklabels(['Died', 'recovered']);\n",
        "ax.set(yticks=[0, 2], \n",
        "       xticks=[0.5, 1.5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "OiMFcBhpj6yH",
        "outputId": "af573b91-beea-4181-a4b8-6603431e94e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.981066\n",
            "AUC: 0.981120\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Recovered       0.98      0.98      0.98       725\n",
            "        Died       0.98      0.98      0.98       701\n",
            "\n",
            "    accuracy                           0.98      1426\n",
            "   macro avg       0.98      0.98      0.98      1426\n",
            "weighted avg       0.98      0.98      0.98      1426\n",
            "\n",
            "[[709  16]\n",
            " [ 11 690]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[<matplotlib.axis.YTick at 0x7fc312353a50>,\n",
              "  <matplotlib.axis.YTick at 0x7fc3122bee90>],\n",
              " [<matplotlib.axis.XTick at 0x7fc3281fe650>,\n",
              "  <matplotlib.axis.XTick at 0x7fc3122be990>]]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "precision, recall, thresholds = precision_recall_curve(validation_y,pre_y)\n",
        "plt.plot(precision,recall)\n",
        "plt.ylabel('Recall')\n",
        "plt.xlabel('Precision')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "XE2S2HsuxBYl",
        "outputId": "3e20f5ac-810a-4b29-c13b-1ef7da62ccb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAYlElEQVR4nO3dfZAcd33n8fdnd2e9M7Y0DUgUKUtGhshHlBwPzsa4LnVnX3Bysv+wAiGUVSHBFEEkhQkXSOrMkTKU74+E4yqpouKEE+ADXBccQ91xujoFhQLzUBQGrWPj80NM7QkcS1DlxciyHVkPu/u9P7pndjSa1Y6t6YfZ/ryqtjTT3TP9bT195te/6W8rIjAzs/qaKLsAMzMrl4PAzKzmHARmZjXnIDAzqzkHgZlZzU2VXcDztWnTpti2bVvZZZiZjZV77733JxGxedC6sQuCbdu2MTc3V3YZZmZjRdJjq63zqSEzs5pzEJiZ1ZyDwMys5hwEZmY15yAwM6u53IJA0u2SnpD04CrrJeljkuYlPSDp8rxqMTOz1eU5Ivg0sPMc668Ftmc/e4C/zrEWMzNbRW7XEUTENyRtO8cmu4DPRtoH+x5JiaSfiYgf51HPwR/+lG9+fwFJTE6kPxMSE6L7OP0VJibEpLL1E2Jygmxbrbrt5ISQ6Hmc7UdiInv9Wa/tWTYxscZrs1rMzEatzAvKLgYe73l+OFt2VhBI2kM6auCSSy55QTv7h8eO8rGvzr+g11bJwBDJwqwbIp11fSHS+7qVbel5n87r0uXdIOwLs0l1wmrAa3vDtRuoPeHaDUMG7HOVcF3rtecK5jPqXSOYzxHqZuvZWFxZHBF7gb0As7OzL+hOOu+66pW866pXEhEsLQdLEUTQfby8HCxnz5ezbZYjWF6Gpex5RPQ8HuK1ESwtM9xrs8f9r13uLF91W7r7TI8pe9x57YBj6b5f0H2fpQgWl5c5uRgsZcvPPBa6rxt8DCv1nHkM6bJxt9oI7Vyju25wrTqyHE0wr2w7YDTbG67dUFz54HDGa884hnyD+czfm8HB7AAuTplBcATY2vN8S7YsV5KYmtR4JOA6claIdEKiEyJ9QdUbIt2g63/tGSGZvXaVkDwjXLtBGD1ByOAPCQOCuX/fS8urvPaMYxlUS1r3qcXlNT5Q0HP8K/s88336PiRkdYyzzqisM5o9M3wGh9DgU7SDgnnt0exEFsyDThWfMcrs2+e5gzl9/9dsTXj1lqTs3+KuMv8/3AfcJOlO4PXAsbzmB6x8ExNiAtGYLLuS+oiIwSO0/tAcMDqMntFs/8jyrJHqaq89K9QHjVT7PyQMeG03sFd/7cq2cPbIui/os9+D00vLa39IyD5kDArmM7dd+YAyjO0vvYgvv++qnP8GDC+3IJD0OeBqYJOkw8CHgAZARHwc2A9cB8wDx4G351WLWR31nmqy4vSODrsh0jPi+9P9j/CVf3yi7DLPkOe3hnavsT6Ad+e1fzOzMqx1+vll7RmeOn6K5eWozDcBfWWxmVmB2s0GywHPnlosu5QuB4GZWYHazQYAx46fLrmSFQ4CM7MCJa1pAJ5yEJiZ1VPSykYEzzkIzMxqKclODT313KmSK1nhIDAzK1A7GxH41JCZWU11J4t9asjMrJ4umJqk2ZjkqeM+NWRmVltJq+FTQ2ZmddZuNnjKp4bMzOoraTU8R2BmVmdJc9pXFpuZ1VnSavg6AjOzOms3PVlsZlZr7VaDk4vLnDi9VHYpgIPAzKxwSbNajeccBGZmBata4zkHgZlZwbqN5ypydbGDwMysYN3Gcx4RmJnVU+fmNFW5lsBBYGZWsHbF7kngIDAzK9iF05NMTcjfGjIzqytJ2dXFDgIzs9pqN6vTeM5BYGZWgqRVncZzDgIzsxIkzeo0nnMQmJmVoF2hu5Q5CMzMStBuNnxqyMyszpLmNM+cXOT00nLZpTgIzMzK0Gk893QFvjnkIDAzK0GVOpDmGgSSdkp6VNK8pJsHrL9E0t2S7pP0gKTr8qzHzKwqVtpMrOMgkDQJ3AZcC+wAdkva0bfZnwB3RcTrgBuAv8qrHjOzKqlS47k8RwRXAPMRcSgiTgF3Arv6tglgY/a4Dfwox3rMzCqjSo3n8gyCi4HHe54fzpb1+jDwVkmHgf3Aewa9kaQ9kuYkzS0sLORRq5lZoVZuTrO+RwTD2A18OiK2ANcBd0g6q6aI2BsRsxExu3nz5sKLNDMbtY01CYIjwNae51uyZb3eAdwFEBHfBmaATTnWZGZWCZMTYuPM1Lr/1tBBYLukSyVNk04G7+vb5p+ANwBI+jnSIPC5HzOrhaQ1vb6DICIWgZuAA8AjpN8OekjSrZKuzzZ7P/BOSd8DPgfcGBGRV01mZlWStBqVuIH9VJ5vHhH7SSeBe5fd0vP4YeCX86zBzKyq2s1q3Jym7MliM7PaqkrjOQeBmVlJqnK7SgeBmVlJkmY6WVz21KiDwMysJEmrwdJy8OzJxVLrcBCYmZWkXZGLyhwEZmYl6TaeK3mewEFgZlaSzj0JPCIwM6upqnQgdRCYmZWkKh1IHQRmZiXpdCD1HIGZWU3NNCZpNiYdBGZmdVaFxnMOAjOzErWbDc8RmJnVWRU6kDoIzMxKlLTK70DqIDAzK1HSnPZ1BGZmdZZOFntEYGZWW+1Wg5OLy5w4vVRaDQ4CM7MSJc3yG885CMzMSlSFxnMOAjOzEq3ck6C8CWMHgZlZiVY6kHpEYGZWS51TQ2VeS+AgMDMrUecuZWVeS+AgMDMr0YXTk0xNyN8aMjOrK0mlX1TmIDAzK1nZjeccBGZmJWs3y2085yAwMytZ0iq38ZyDwMysZEnJN6fJNQgk7ZT0qKR5STevss1bJD0s6SFJf5NnPWZmVdQu+Z4EU3m9saRJ4DbgV4HDwEFJ+yLi4Z5ttgMfAH45Io5Kemle9ZiZVVXSnOaZk4ssLi0zNVn8iZo893gFMB8RhyLiFHAnsKtvm3cCt0XEUYCIeCLHeszMKqlzdfHTJxZL2X+eQXAx8HjP88PZsl6XAZdJ+pakeyTtHPRGkvZImpM0t7CwkFO5ZmblKLvxXNmTxVPAduBqYDfwCUlJ/0YRsTciZiNidvPmzQWXaGaWr3ar3MZzeQbBEWBrz/Mt2bJeh4F9EXE6In4AfJ80GMzMaiNpltt4Ls8gOAhsl3SppGngBmBf3zZfJB0NIGkT6amiQznWZGZWOWU3nsstCCJiEbgJOAA8AtwVEQ9JulXS9dlmB4AnJT0M3A38cUQ8mVdNZmZVVPaIILevjwJExH5gf9+yW3oeB/C+7MfMrJY2lnxzmrIni83Mam9yQmycmSrt6mIHgZlZBbRbjdLuSeAgMDOrgKQ5Xdp1BOecI5D0DBCDVpGe4t+YS1VmZjWTtMq7J8E5gyAiNhRViJlZnbWbDY4cfa6Ufa81InjxudZHxE9HW46ZWT0lJc4RrPX10XtJTw1pwLoAXjHyiszMaihpTvPUc6eJCKRB/+XmZ61TQ5cWVYiZWZ0lrQZLy8GzJxfZMNModN9DX1Am6UWkfYBmOssi4ht5FGVmVjfdi8qOn65mEEj6XeC9pI3j7geuBL4N/Ep+pZmZ1Ue3zcRzp8/o1lmEYa8jeC/wS8BjEfFvgdcBT+VWlZlZzXQbz5VwdfGwQXAiIk4ASLogIv4R+Bf5lWVmVi9J954ExV9UNuwcweHshjFfBL4s6SjwWH5lmZnVS++poaINFQQR8cbs4Ycl3Q20gS/lVpWZWc30ThYXbahTQ5KulLQBICK+DnyNdJ7AzMxGYKYxyUxjopQRwbBzBH8NPNvz/NlsmZmZjUhZjeeGDQJlN5EBICKWyfmmNmZmdZO0GtU9NQQckvQHkhrZz3vxvYXNzEaq3SynA+mwQfB7wL8CjgCHgdcDe/IqysysjpJWo5T7Fg/7raEngBtyrsXMrNaS5jTHnjtW+H6H/dbQZZK+IunB7PmrJf1JvqWZmdVLenOa6k4WfwL4AHAaICIewCMEM7OR2thscOL0MidOLxW632GDoBUR3+1btjjqYszM6qzTZqLoawmGDYKfSHol2f2LJb0Z+HFuVZmZ1VDSLKfx3LDXArwb2Au8StIR4AfAb+VWlZlZDXUbzxV8Udmw3xo6BFwj6ULSUcRx0jkCN54zMxuRdqffUJVODUnaKOkDkv5S0q+SBsDbgHngLUUUaGZWF2XNEaw1IrgDOEp6N7J3Ah8kvZH9GyPi/pxrMzOrlc7NaYq+qGytIHhFRPxLAEmfJJ0gvqRzkxozMxudC6cnmZxQ4dcSrPWtoW4sRcQScNghYGaWD0kkzeIbz601IniNpKezxwKa2XMBEREbc63OzKxm2q3iG8+dc0QQEZMRsTH72RARUz2P1wwBSTslPSppXtLN59juNySFpNkXchBmZutF0iy+8dywF5Q9b5ImgduAa4EdwG5JOwZstwF4L/CdvGoxMxsXSWu6slcWvxBXAPMRcSgiTgF3ArsGbPefgI8Annsws9pLmsU3nsszCC4GHu95fjhb1iXpcmBrRPyfc72RpD2S5iTNLSwsjL5SM7OK2FjCZHGeQXBOkiaAPwfev9a2EbE3ImYjYnbz5s35F2dmVpKk1eCZE4ssLi0Xts88g+AIsLXn+ZZsWccG4BeAr0n6IXAlsM8TxmZWZ0nWZuLpE8U1eM4zCA4C2yVdKmmatDfRvs7KiDgWEZsiYltEbAPuAa6PiLkcazIzq7TO1cVFNp7LLQgiYhG4CTgAPALcFREPSbpV0vV57dfMbJy1W8U3nhu2DfULEhH7gf19y25ZZdur86zFzGwcdE4NFfkV0tImi83M7GxlNJ5zEJiZVUj3ngTrYY7AzMyev40z6Rn7IucIHARmZhUyNTnBhpmpQi8qcxCYmVVM0mp4stjMrM6S5rTnCMzM6swjAjOzmms3i705jYPAzKxi2gXfnMZBYGZWMUl2u8qIKGR/DgIzs4pJmtMsLQfPniymA6mDwMysYrqN5wo6PeQgMDOrmKIbzzkIzMwqptt4zkFgZlZPK43nHARmZrWUdG9OU8zVxQ4CM7OK8YjAzKzmZhqTzDQmPEdgZlZnRTaecxCYmVVQ0mr41JCZWZ21m8V1IHUQmJlVkIPAzKzmfGrIzKzmkta0ryMwM6uzdrPBidPLnDi9lPu+HARmZhXUubq4iHkCB4GZWQUlzeIazzkIzMwqKCnwngQOAjOzClrpN5T/hLGDwMysgrpBMO6nhiTtlPSopHlJNw9Y/z5JD0t6QNJXJL08z3rMzMZFd7J4nE8NSZoEbgOuBXYAuyXt6NvsPmA2Il4NfAH4z3nVY2Y2Ti66YIrJCRVyLUGeI4IrgPmIOBQRp4A7gV29G0TE3RFxPHt6D7Alx3rMzMaGJJJmMVcX5xkEFwOP9zw/nC1bzTuAvxu0QtIeSXOS5hYWFkZYoplZdbVbxfQbqsRksaS3ArPARwetj4i9ETEbEbObN28utjgzs5IU1XhuKsf3PgJs7Xm+JVt2BknXAB8EroqIkznWY2Y2VpJmg588O95zBAeB7ZIulTQN3ADs691A0uuA/wpcHxFP5FiLmdnYKarxXG5BEBGLwE3AAeAR4K6IeEjSrZKuzzb7KHAR8HlJ90vat8rbmZnVTrugyeI8Tw0REfuB/X3Lbul5fE2e+zczG2dJq8EzJxZZXFpmajK/EziVmCw2M7OzJdnVxU+fWMx1Pw4CM7OKSlrFdCB1EJiZVVRRjeccBGZmFdVuFdN4zkFgZlZRnTmCvBvPOQjMzCqqM0fgU0NmZjW1cSb9hr9PDZmZ1dTU5AQbZqZyv6jMQWBmVmHtZoOnPSIwM6uvpNXwqSEzszpLmtOeLDYzq7O2RwRmZvWWNBu+jsDMrM46cwQRkds+HARmZhWWNKdZWg7++dRSbvtwEJiZVVgRjeccBGZmFdZtPJfjPIGDwMyswrqN53L85pCDwMyswlYazzkIzMxqKenek8BzBGZmtbQyWewRgZlZLc00JplpTOTaeM5BYGZWce1mwyMCM7M6S5rTniMwM6uzdssjAjOzWkuaDV9HYGZWZ4lHBGZm9Za0PEdgZlZr7WaDE6eXOXE6nw6kDgIzs4rrXFSW17UEDgIzs4pbaTMxhkEgaaekRyXNS7p5wPoLJP1ttv47krblWY+Z2ThKmvk2nsstCCRNArcB1wI7gN2SdvRt9g7gaET8LPAXwEfyqsfMbFx1RwQ53ZwmzxHBFcB8RByKiFPAncCuvm12AZ/JHn8BeIMk5ViTmdnY6TaeG8NTQxcDj/c8P5wtG7hNRCwCx4CX9L+RpD2S5iTNLSws5FSumVk1vfjCaXb+/Mt42caZXN5/Kpd3HbGI2AvsBZidnY2SyzEzK9SFF0zx8d/+xdzeP88RwRFga8/zLdmygdtImgLawJM51mRmZn3yDIKDwHZJl0qaBm4A9vVtsw94W/b4zcBXI8Kf+M3MCpTbqaGIWJR0E3AAmARuj4iHJN0KzEXEPuBTwB2S5oGfkoaFmZkVKNc5gojYD+zvW3ZLz+MTwG/mWYOZmZ2bryw2M6s5B4GZWc05CMzMas5BYGZWcxq3b2tKWgAeG+FbbgJ+MsL3qzof7/rm413fzud4Xx4RmwetGLsgGDVJcxExW3YdRfHxrm8+3vUtr+P1qSEzs5pzEJiZ1ZyDIGtmVyM+3vXNx7u+5XK8tZ8jMDOrO48IzMxqzkFgZlZztQkCSTslPSppXtLNA9bfKGlB0v3Zz++WUeeorHW82TZvkfSwpIck/U3RNY7SEH++f9HzZ/t9SU+VUeeoDHG8l0i6W9J9kh6QdF0ZdY7CEMf6cklfyY7za5K2lFHnqEi6XdITkh5cZb0kfSz7/XhA0uXnvdOIWPc/pG2w/x/wCmAa+B6wo2+bG4G/LLvWAo93O3Af8KLs+UvLrjvP4+3b/j2kbdFLrz3HP9+9wO9nj3cAPyy77hyP9fPA27LHvwLcUXbd53nM/wa4HHhwlfXXAX8HCLgS+M757rMuI4IrgPmIOBQRp4A7gV0l15SnYY73ncBtEXEUICKeKLjGUXq+f767gc8VUlk+hjneADZmj9vAjwqsb5SGOdYdwFezx3cPWD9WIuIbpPdnWc0u4LORugdIJP3M+eyzLkFwMfB4z/PD2bJ+v5ENtb4gaeuA9eNimOO9DLhM0rck3SNpZ2HVjd6wf75IejlwKSv/cYyjYY73w8BbJR0mvSfIe4opbeSGOdbvAW/KHr8R2CDpJQXUVpah/74Pqy5BMIz/DWyLiFcDXwY+U3I9eZsiPT10Nekn5E9ISkqtqBg3AF+IiKWyC8nZbuDTEbGF9FTCHZLW67/3PwKuknQfcBXpvdDX+5/vSK3Xvxj9jgC9n/C3ZMu6IuLJiDiZPf0k8IsF1ZaHNY+X9FPEvog4HRE/AL5PGgzjaJjj7biB8T4tBMMd7zuAuwAi4tvADGnDsnEzzL/dH0XEmyLidcAHs2Vj/WWANTyfv+9DqUsQHAS2S7pU0jTpfwb7ejfoO8d2PfBIgfWN2prHC3yRdDSApE2kp4oOFVnkCA1zvEh6FfAi4NsF1zdqwxzvPwFvAJD0c6RBsFBolaMxzL/dTT2jnQ8AtxdcY9H2Ab+TfXvoSuBYRPz4fN4w13sWV0VELEq6CThA+i2E2yPiIUm3AnMRsQ/4A0nXA4ukEzU3llbweRryeA8AvybpYdJh9B9HxJPlVf3CDXm8kP4ncmdkX70YV0Me7/tJT/f9IenE8Y3jeNxDHuvVwJ9KCuAbwLtLK3gEJH2O9Jg2ZXM8HwIaABHxcdI5n+uAeeA48Pbz3ucY/t0wM7MRqsupITMzW4WDwMys5hwEZmY15yAwM6s5B4GZWc05CKyWJC1lnUgflPR5Sa0RvOetkq45x/rfk/Q757sfs1Hz10etliQ9GxEXZY//O3BvRPx5z/qpiFgsrUCzAnlEYAbfBH5W0tWSvilpH/CwpElJH5V0MGtG+K7OCyT9B0n/V9L3JP1ZtuzTkt6cPf6z7F4PD0j6L9myD0v6o+zxa7Nmfw9I+p+SXpQt/5qkj0j6bnbfhH9d9G+G1U8triw2W42kKeBa4EvZosuBX4iIH0jaQ3r5/i9JugD4lqS/B15F2gr49RFxXNKL+97zJaRdMF8VEbFKM7/PAu+JiK9nV8l+CPj32bqpiLgiu5nMh4BVTzeZjYJHBFZXTUn3A3OkfXk+lS3/btaED+DXSHu63A98B3gJaWO+a4D/FhHHASKiv3f8MeAE8ClJbyJtA9AlqQ0kEfH1bNFnSG9G0vE/sl/vBbadz0GaDcMjAqur5yLitb0LJAH8c+8i0k/tB/q2+3fneuOsP84VpE3f3gzcRHrnrGF1uuAu4X+jVgCPCMxWdwD4fUkNAEmXSbqQ9H4Vb+9802jAqaGLgHZE7Af+EHhN7/qIOAYc7Tn//9vA1zEriT9tmK3uk6SnZv5B6XBhAfj1iPiSpNcCc5JOkXaD/I89r9sA/C9JM6SjivcNeO+3AR/PwuQQI+ggafZC+eujZmY151NDZmY15yAwM6s5B4GZWc05CMzMas5BYGZWcw4CM7OacxCYmdXc/wfu6HwBxJFPVwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}