{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "whrVagVehwQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPOhEunFmHk9",
        "outputId": "51ed04d1-64d4-4a6f-808b-906dd6e972bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D,Conv1D\n",
        "from keras.layers import MaxPooling1D,MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import AveragePooling1D,AveragePooling2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers import Dropout\n",
        "from keras import regularizers\n",
        "from tensorflow.keras.optimizers import SGD, Adam, Adamax, Adadelta\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score, f1_score, recall_score, roc_auc_score, confusion_matrix"
      ],
      "metadata": {
        "id": "VFn3J28Um19h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/gdrive/MyDrive/Risk Prediction/Dataset/PreprocessedData.csv',index_col=[0])"
      ],
      "metadata": {
        "id": "LsSx8-jNm9WH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "2K52TKNLzGj8",
        "outputId": "646f2946-153f-457e-eee2-e022b82221f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Derivation cohort  LOS_Y  LOS  Age  Severity  White  COPD  Renal Disease  \\\n",
              "0                  1      1    1  >80         3      0     0              0   \n",
              "1                  1      1    2  >60         7      1     0              0   \n",
              "2                  1      1    2  >80         7      1     1              1   \n",
              "3                  1      1   15  >70         9      0     0              0   \n",
              "4                  1      1    9  >70         7      0     0              0   \n",
              "\n",
              "   All CNS  Pure CNS  ...  Ferritin > 300  CrctProtein  C-Reactive Prot > 10  \\\n",
              "0        0         0  ...               0    -0.874517                     0   \n",
              "1        0         0  ...               1     0.408530                     1   \n",
              "2        0         0  ...               1     2.101429                     1   \n",
              "3        1         1  ...               1     0.720380                     1   \n",
              "4        0         0  ...               1     0.114501                     1   \n",
              "\n",
              "   ProCalCYes  Procalcitonin  Procalciton > 0.1  TropYes  Troponin  \\\n",
              "0           0      -0.253185                  0        1 -0.154975   \n",
              "1           1      -0.157378                  1        1  4.282678   \n",
              "2           1      -0.061572                  1        0 -0.192266   \n",
              "3           1       0.912461                  1        1 -0.005810   \n",
              "4           0      -0.253185                  0        1 -0.154975   \n",
              "\n",
              "   Troponin > 0.1  Death  \n",
              "0               0      0  \n",
              "1               1      1  \n",
              "2               0      1  \n",
              "3               0      0  \n",
              "4               0      0  \n",
              "\n",
              "[5 rows x 55 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-39f053f7-5c2d-4621-b7eb-c9f87a9925a7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Derivation cohort</th>\n",
              "      <th>LOS_Y</th>\n",
              "      <th>LOS</th>\n",
              "      <th>Age</th>\n",
              "      <th>Severity</th>\n",
              "      <th>White</th>\n",
              "      <th>COPD</th>\n",
              "      <th>Renal Disease</th>\n",
              "      <th>All CNS</th>\n",
              "      <th>Pure CNS</th>\n",
              "      <th>...</th>\n",
              "      <th>Ferritin &gt; 300</th>\n",
              "      <th>CrctProtein</th>\n",
              "      <th>C-Reactive Prot &gt; 10</th>\n",
              "      <th>ProCalCYes</th>\n",
              "      <th>Procalcitonin</th>\n",
              "      <th>Procalciton &gt; 0.1</th>\n",
              "      <th>TropYes</th>\n",
              "      <th>Troponin</th>\n",
              "      <th>Troponin &gt; 0.1</th>\n",
              "      <th>Death</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>&gt;80</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.874517</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.253185</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.154975</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>&gt;60</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.408530</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.157378</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.282678</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>&gt;80</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>2.101429</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.061572</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.192266</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>&gt;70</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.720380</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.912461</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.005810</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>&gt;70</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.114501</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.253185</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.154975</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 55 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-39f053f7-5c2d-4621-b7eb-c9f87a9925a7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-39f053f7-5c2d-4621-b7eb-c9f87a9925a7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-39f053f7-5c2d-4621-b7eb-c9f87a9925a7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "-otKsJoIwz3v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37e8e3a0-4d93-4197-e847-b54fa89505f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4711, 55)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.drop(4710)\n",
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-oVzAXP3r9H",
        "outputId": "9be610ff-281e-48af-b04a-83212f2088b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4710, 55)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "req_features=['LOS_Y', 'LOS', 'Severity',\n",
        "       'All CNS', 'Pure CNS', 'Age.1', 'AgeScore', 'O2 Sat < 94', 'MAP < 70', 'Ddimer', 'D-Dimer > 3', 'PltsScore', 'INRYes', 'INR', 'INR > 1.2', 'BUN',\n",
        "       'BUN > 30', 'Creatinine', 'CrtnScore',\n",
        "       'Sodium < 139 or > 154', 'AST', 'AST > 40', 'WBC', 'WBC <1.8 or > 4.8',\n",
        "       'Lymphocytes < 1', 'IL6 > 150',\n",
        "       'Ferritin', 'Ferritin > 300', 'CrctProtein',\n",
        "       'C-Reactive Prot > 10', 'Procalcitonin',\n",
        "       'Procalciton > 0.1', 'TropYes', 'Troponin', 'Troponin > 0.1']"
      ],
      "metadata": {
        "id": "a5PQ-Ddsw8V_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=df[req_features]"
      ],
      "metadata": {
        "id": "s8yjXVVCw_03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y=df['Death']"
      ],
      "metadata": {
        "id": "ByW9q14cxCz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, Y, test_size=0.2, random_state=2)\n",
        "print(X_train1.shape)\n",
        "print(y_train1.shape)\n",
        "print(X_test1.shape)\n",
        "print(y_test1.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqcAmTk4TIVr",
        "outputId": "1cc88c19-2dba-400c-c67d-8ccfd570893c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3768, 35)\n",
            "(3768,)\n",
            "(942, 35)\n",
            "(942,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "#model.add(BatchNormalization(input_shape=(35,1)))\n",
        "model.add(Reshape((7,5,1), input_shape=(35,1)))\n",
        "print(\"shape is {}\".format(model.output_shape))\n",
        "model.add(TimeDistributed(LSTM(256, activation='tanh',return_sequences = True)))\n",
        "model.add(Dropout(0.6))\n",
        "#model.add(BatchNormalization())\n",
        "model.add(TimeDistributed(Conv1D(256, kernel_size=4, activation='relu', \n",
        "                                 padding=\"same\",\n",
        "                                 kernel_regularizer=regularizers.l2(0.01), \n",
        "                                 bias_regularizer=regularizers.l2(0.01))))\n",
        "model.add(Conv1D(filters=256, kernel_size=3, strides=1, activation='relu'))\n",
        "model.add(AveragePooling2D((2,2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(units=128, activation='relu'))\n",
        "model.add(Dense(units=64, activation='relu'))\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "EyfoWWAExERG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a891c7c-9f76-4de5-c49e-6e54980f859f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape is (None, 7, 5, 1)\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape (Reshape)           (None, 7, 5, 1)           0         \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 7, 5, 256)        264192    \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 7, 5, 256)         0         \n",
            "                                                                 \n",
            " time_distributed_1 (TimeDis  (None, 7, 5, 256)        262400    \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 7, 3, 256)         196864    \n",
            "                                                                 \n",
            " average_pooling2d (AverageP  (None, 3, 1, 256)        0         \n",
            " ooling2D)                                                       \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 768)               0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 768)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               98432     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 830,209\n",
            "Trainable params: 830,209\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opt=Adam(learning_rate= 0.0001)"
      ],
      "metadata": {
        "id": "q4wJoc2x3YvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer= opt,\n",
        "              metrics='accuracy')"
      ],
      "metadata": {
        "id": "VqcYzra_xZlv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = KFold(n_splits=10, shuffle=False)"
      ],
      "metadata": {
        "id": "IRMZ6XQ9xfJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "j=1           \n",
        "i=1\n",
        "for train_index, test_index in kfold.split(df):\n",
        "    X4 = df.iloc[train_index].loc[:, req_features]\n",
        "    X5 = df.iloc[test_index][req_features]\n",
        "    y4= df.iloc[train_index].loc[:,'Death']\n",
        "    y5 = df.loc[test_index]['Death']\n",
        "\n",
        "    X6= X4.to_numpy('float64')\n",
        "    X7=np.resize(X6,(4239,35,1))\n",
        "    X8= X5.to_numpy('float64')\n",
        "    X9=np.resize(X8,(471,35,1))\n",
        "    y6=y4.to_numpy('int')    #train output\n",
        "    y7=y5.to_numpy('int')\n",
        "    train_x = X7\n",
        "    train_y = y6\n",
        "    validation_x = X9\n",
        "    validation_y = y7\n",
        "    history= model.fit(train_x , train_y, epochs=10, batch_size=12,verbose=1) #Training the model\n",
        "    ypre=model.predict(validation_x)\n",
        "    pre_y=np.round(abs(ypre))\n",
        "    print(f\"Accuracy for the fold no. {i} on the test set: {accuracy_score(validation_y, pre_y )}\")\n",
        "    accuracy = accuracy_score(validation_y, pre_y)\n",
        "    print('Accuracy: %f' % accuracy)\n",
        "    matrix = confusion_matrix(validation_y, pre_y)\n",
        "    print(matrix)\n",
        "    i+= 1 \n",
        "    j=j+1"
      ],
      "metadata": {
        "id": "V6e9VYg1xvT_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28a5a2ee-e403-4101-c46c-3b92f9518b12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "354/354 [==============================] - 17s 12ms/step - loss: 1.7821 - accuracy: 0.7540\n",
            "Epoch 2/10\n",
            "354/354 [==============================] - 4s 11ms/step - loss: 0.7347 - accuracy: 0.7634\n",
            "Epoch 3/10\n",
            "354/354 [==============================] - 4s 11ms/step - loss: 0.5457 - accuracy: 0.7622\n",
            "Epoch 4/10\n",
            "354/354 [==============================] - 4s 10ms/step - loss: 0.5022 - accuracy: 0.7646\n",
            "Epoch 5/10\n",
            "354/354 [==============================] - 4s 11ms/step - loss: 0.4849 - accuracy: 0.7693\n",
            "Epoch 6/10\n",
            "354/354 [==============================] - 4s 11ms/step - loss: 0.4791 - accuracy: 0.7662\n",
            "Epoch 7/10\n",
            "354/354 [==============================] - 4s 11ms/step - loss: 0.4668 - accuracy: 0.7764\n",
            "Epoch 8/10\n",
            "354/354 [==============================] - 4s 11ms/step - loss: 0.4669 - accuracy: 0.7698\n",
            "Epoch 9/10\n",
            "354/354 [==============================] - 4s 11ms/step - loss: 0.4668 - accuracy: 0.7719\n",
            "Epoch 10/10\n",
            "354/354 [==============================] - 4s 11ms/step - loss: 0.4667 - accuracy: 0.7712\n",
            "Accuracy for the fold no. 1 on the test set: 0.7749469214437368\n",
            "Accuracy: 0.774947\n",
            "[[319  28]\n",
            " [ 78  46]]\n",
            "Epoch 1/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4661 - accuracy: 0.7702\n",
            "Epoch 2/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4609 - accuracy: 0.7754\n",
            "Epoch 3/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4617 - accuracy: 0.7745\n",
            "Epoch 4/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4590 - accuracy: 0.7768\n",
            "Epoch 5/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4594 - accuracy: 0.7759\n",
            "Epoch 6/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4589 - accuracy: 0.7757\n",
            "Epoch 7/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4600 - accuracy: 0.7778\n",
            "Epoch 8/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4563 - accuracy: 0.7712\n",
            "Epoch 9/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4565 - accuracy: 0.7749\n",
            "Epoch 10/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4559 - accuracy: 0.7761\n",
            "Accuracy for the fold no. 2 on the test set: 0.7388535031847133\n",
            "Accuracy: 0.738854\n",
            "[[332  11]\n",
            " [112  16]]\n",
            "Epoch 1/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4563 - accuracy: 0.7782\n",
            "Epoch 2/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4495 - accuracy: 0.7832\n",
            "Epoch 3/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4544 - accuracy: 0.7761\n",
            "Epoch 4/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4528 - accuracy: 0.7823\n",
            "Epoch 5/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4469 - accuracy: 0.7816\n",
            "Epoch 6/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4454 - accuracy: 0.7867\n",
            "Epoch 7/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4509 - accuracy: 0.7823\n",
            "Epoch 8/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4484 - accuracy: 0.7832\n",
            "Epoch 9/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4476 - accuracy: 0.7870\n",
            "Epoch 10/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4479 - accuracy: 0.7884\n",
            "Accuracy for the fold no. 3 on the test set: 0.7707006369426752\n",
            "Accuracy: 0.770701\n",
            "[[330  13]\n",
            " [ 95  33]]\n",
            "Epoch 1/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4504 - accuracy: 0.7915\n",
            "Epoch 2/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4505 - accuracy: 0.7877\n",
            "Epoch 3/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4471 - accuracy: 0.7905\n",
            "Epoch 4/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4435 - accuracy: 0.7919\n",
            "Epoch 5/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4447 - accuracy: 0.7936\n",
            "Epoch 6/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4451 - accuracy: 0.7924\n",
            "Epoch 7/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4403 - accuracy: 0.7945\n",
            "Epoch 8/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4372 - accuracy: 0.7997\n",
            "Epoch 9/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4452 - accuracy: 0.7959\n",
            "Epoch 10/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4366 - accuracy: 0.7988\n",
            "Accuracy for the fold no. 4 on the test set: 0.8237791932059448\n",
            "Accuracy: 0.823779\n",
            "[[342   4]\n",
            " [ 79  46]]\n",
            "Epoch 1/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4304 - accuracy: 0.8080\n",
            "Epoch 2/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4355 - accuracy: 0.8061\n",
            "Epoch 3/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4255 - accuracy: 0.8143\n",
            "Epoch 4/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4273 - accuracy: 0.8096\n",
            "Epoch 5/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4290 - accuracy: 0.8162\n",
            "Epoch 6/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4287 - accuracy: 0.8096\n",
            "Epoch 7/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4267 - accuracy: 0.8141\n",
            "Epoch 8/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4200 - accuracy: 0.8129\n",
            "Epoch 9/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4204 - accuracy: 0.8181\n",
            "Epoch 10/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4167 - accuracy: 0.8193\n",
            "Accuracy for the fold no. 5 on the test set: 0.8428874734607219\n",
            "Accuracy: 0.842887\n",
            "[[343  12]\n",
            " [ 62  54]]\n",
            "Epoch 1/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4165 - accuracy: 0.8205\n",
            "Epoch 2/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4143 - accuracy: 0.8212\n",
            "Epoch 3/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4162 - accuracy: 0.8202\n",
            "Epoch 4/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4151 - accuracy: 0.8181\n",
            "Epoch 5/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4106 - accuracy: 0.8228\n",
            "Epoch 6/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4116 - accuracy: 0.8226\n",
            "Epoch 7/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4072 - accuracy: 0.8278\n",
            "Epoch 8/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4094 - accuracy: 0.8219\n",
            "Epoch 9/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4098 - accuracy: 0.8209\n",
            "Epoch 10/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4121 - accuracy: 0.8231\n",
            "Accuracy for the fold no. 6 on the test set: 0.8343949044585988\n",
            "Accuracy: 0.834395\n",
            "[[343   7]\n",
            " [ 71  50]]\n",
            "Epoch 1/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4117 - accuracy: 0.8181\n",
            "Epoch 2/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4103 - accuracy: 0.8205\n",
            "Epoch 3/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4097 - accuracy: 0.8238\n",
            "Epoch 4/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4083 - accuracy: 0.8221\n",
            "Epoch 5/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4077 - accuracy: 0.8217\n",
            "Epoch 6/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4054 - accuracy: 0.8245\n",
            "Epoch 7/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4103 - accuracy: 0.8217\n",
            "Epoch 8/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4117 - accuracy: 0.8205\n",
            "Epoch 9/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4046 - accuracy: 0.8240\n",
            "Epoch 10/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4050 - accuracy: 0.8252\n",
            "Accuracy for the fold no. 7 on the test set: 0.8492569002123143\n",
            "Accuracy: 0.849257\n",
            "[[328  28]\n",
            " [ 43  72]]\n",
            "Epoch 1/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4057 - accuracy: 0.8235\n",
            "Epoch 2/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4053 - accuracy: 0.8200\n",
            "Epoch 3/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4056 - accuracy: 0.8235\n",
            "Epoch 4/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4050 - accuracy: 0.8221\n",
            "Epoch 5/10\n",
            "354/354 [==============================] - 4s 11ms/step - loss: 0.4059 - accuracy: 0.8297\n",
            "Epoch 6/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4047 - accuracy: 0.8266\n",
            "Epoch 7/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4058 - accuracy: 0.8273\n",
            "Epoch 8/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4035 - accuracy: 0.8245\n",
            "Epoch 9/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4046 - accuracy: 0.8290\n",
            "Epoch 10/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.4041 - accuracy: 0.8294\n",
            "Accuracy for the fold no. 8 on the test set: 0.8556263269639066\n",
            "Accuracy: 0.855626\n",
            "[[354  11]\n",
            " [ 57  49]]\n",
            "Epoch 1/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.3876 - accuracy: 0.8353\n",
            "Epoch 2/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.3837 - accuracy: 0.8405\n",
            "Epoch 3/10\n",
            "354/354 [==============================] - 4s 11ms/step - loss: 0.3888 - accuracy: 0.8316\n",
            "Epoch 4/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.3832 - accuracy: 0.8358\n",
            "Epoch 5/10\n",
            "354/354 [==============================] - 4s 11ms/step - loss: 0.3844 - accuracy: 0.8377\n",
            "Epoch 6/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.3837 - accuracy: 0.8346\n",
            "Epoch 7/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.3830 - accuracy: 0.8356\n",
            "Epoch 8/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.3823 - accuracy: 0.8372\n",
            "Epoch 9/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.3825 - accuracy: 0.8386\n",
            "Epoch 10/10\n",
            "354/354 [==============================] - 4s 11ms/step - loss: 0.3834 - accuracy: 0.8360\n",
            "Accuracy for the fold no. 9 on the test set: 0.7876857749469215\n",
            "Accuracy: 0.787686\n",
            "[[346  25]\n",
            " [ 75  25]]\n",
            "Epoch 1/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.3764 - accuracy: 0.8412\n",
            "Epoch 2/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.3763 - accuracy: 0.8417\n",
            "Epoch 3/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.3712 - accuracy: 0.8441\n",
            "Epoch 4/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.3771 - accuracy: 0.8363\n",
            "Epoch 5/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.3757 - accuracy: 0.8365\n",
            "Epoch 6/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.3740 - accuracy: 0.8417\n",
            "Epoch 7/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.3773 - accuracy: 0.8382\n",
            "Epoch 8/10\n",
            "354/354 [==============================] - 4s 11ms/step - loss: 0.3749 - accuracy: 0.8419\n",
            "Epoch 9/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.3764 - accuracy: 0.8415\n",
            "Epoch 10/10\n",
            "354/354 [==============================] - 4s 12ms/step - loss: 0.3719 - accuracy: 0.8398\n",
            "Accuracy for the fold no. 10 on the test set: 0.7537154989384289\n",
            "Accuracy: 0.753715\n",
            "[[341  45]\n",
            " [ 71  14]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "DJhwmO7-ig8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test2=np.resize(X_test1,(942,35,1))   #validation data  \n",
        "y_test2=y_test1.to_numpy('int')    #train output\n",
        "validation_x = X_test2\n",
        "validation_y = y_test2\n",
        "ypre=model.predict(validation_x)\n",
        "pre_y=np.where(ypre>0.5, 1, 0)\n",
        "accuracy = accuracy_score(validation_y, pre_y)\n",
        "auc=metrics.roc_auc_score(validation_y, pre_y)\n",
        "print('Accuracy: %f' % accuracy)\n",
        "print('AUC: %f' % auc)\n",
        "print('Classification Report')\n",
        "target_names = ['Recovered', 'Died']\n",
        "print(classification_report(validation_y, pre_y, target_names=target_names))\n",
        "# confusion matrix\n",
        "matrix = confusion_matrix(validation_y, pre_y)\n",
        "print(matrix)\n",
        "ax=plt.subplot()\n",
        "sns.heatmap(matrix,annot=True,ax=ax,cmap='OrRd_r', fmt='g')#annot=True to annotate cells, fmt='g' numbers not scientific form\n",
        "ax.set_xlabel('Predicted labels'); \n",
        "ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix'); \n",
        "ax.xaxis.set_ticklabels(['Died', 'recovered']); \n",
        "ax.yaxis.set_ticklabels(['Died', 'recovered']);\n",
        "ax.set(yticks=[0, 2], \n",
        "       xticks=[0.5, 1.5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "BoAThDJYgUE7",
        "outputId": "5131dfa7-928e-4ff1-b980-e5c27b93d604"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.848195\n",
            "AUC: 0.712339\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Recovered       0.87      0.95      0.91       736\n",
            "        Died       0.74      0.47      0.58       206\n",
            "\n",
            "    accuracy                           0.85       942\n",
            "   macro avg       0.80      0.71      0.74       942\n",
            "weighted avg       0.84      0.85      0.83       942\n",
            "\n",
            "[[702  34]\n",
            " [109  97]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[<matplotlib.axis.YTick at 0x7f391d551d10>,\n",
              "  <matplotlib.axis.YTick at 0x7f391d4377d0>],\n",
              " [<matplotlib.axis.XTick at 0x7f391d4f3dd0>,\n",
              "  <matplotlib.axis.XTick at 0x7f391d551810>]]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "precision, recall, thresholds = precision_recall_curve(validation_y,pre_y)\n",
        "plt.plot(precision,recall)\n",
        "plt.ylabel('Recall')\n",
        "plt.xlabel('Precision')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "WiUBRQMlxNqO",
        "outputId": "1e852dd9-8aa9-46e7-cbb3-35bf61015cdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "CV-LSTM",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}