{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CV-CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBGEVg-68g31",
        "outputId": "e378cfbd-d928-4751-b824-35bf65225c1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D,Conv1D\n",
        "from keras.layers import MaxPooling1D,MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten"
      ],
      "metadata": {
        "id": "qsk4cQqW9lNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/gdrive/MyDrive/Risk Prediction/Dataset/PreprocessedData.csv',index_col=[0])"
      ],
      "metadata": {
        "id": "9qIobnq0_ANK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "KyGFM1hW_j3S",
        "outputId": "d9bb494b-456b-4784-8cf4-f6daa3c22bcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Derivation cohort  LOS_Y  LOS  Age  Severity  White  COPD  Renal Disease  \\\n",
              "0                  1      1    1  >80         3      0     0              0   \n",
              "1                  1      1    2  >60         7      1     0              0   \n",
              "2                  1      1    2  >80         7      1     1              1   \n",
              "3                  1      1   15  >70         9      0     0              0   \n",
              "4                  1      1    9  >70         7      0     0              0   \n",
              "\n",
              "   All CNS  Pure CNS  ...  Ferritin > 300  CrctProtein  C-Reactive Prot > 10  \\\n",
              "0        0         0  ...               0    -0.874517                     0   \n",
              "1        0         0  ...               1     0.408530                     1   \n",
              "2        0         0  ...               1     2.101429                     1   \n",
              "3        1         1  ...               1     0.720380                     1   \n",
              "4        0         0  ...               1     0.114501                     1   \n",
              "\n",
              "   ProCalCYes  Procalcitonin  Procalciton > 0.1  TropYes  Troponin  \\\n",
              "0           0      -0.253185                  0        1 -0.154975   \n",
              "1           1      -0.157378                  1        1  4.282678   \n",
              "2           1      -0.061572                  1        0 -0.192266   \n",
              "3           1       0.912461                  1        1 -0.005810   \n",
              "4           0      -0.253185                  0        1 -0.154975   \n",
              "\n",
              "   Troponin > 0.1  Death  \n",
              "0               0      0  \n",
              "1               1      1  \n",
              "2               0      1  \n",
              "3               0      0  \n",
              "4               0      0  \n",
              "\n",
              "[5 rows x 55 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f76cae7d-0f4e-4b5f-952a-72ef67d1c16e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Derivation cohort</th>\n",
              "      <th>LOS_Y</th>\n",
              "      <th>LOS</th>\n",
              "      <th>Age</th>\n",
              "      <th>Severity</th>\n",
              "      <th>White</th>\n",
              "      <th>COPD</th>\n",
              "      <th>Renal Disease</th>\n",
              "      <th>All CNS</th>\n",
              "      <th>Pure CNS</th>\n",
              "      <th>...</th>\n",
              "      <th>Ferritin &gt; 300</th>\n",
              "      <th>CrctProtein</th>\n",
              "      <th>C-Reactive Prot &gt; 10</th>\n",
              "      <th>ProCalCYes</th>\n",
              "      <th>Procalcitonin</th>\n",
              "      <th>Procalciton &gt; 0.1</th>\n",
              "      <th>TropYes</th>\n",
              "      <th>Troponin</th>\n",
              "      <th>Troponin &gt; 0.1</th>\n",
              "      <th>Death</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>&gt;80</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.874517</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.253185</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.154975</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>&gt;60</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.408530</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.157378</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.282678</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>&gt;80</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>2.101429</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.061572</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.192266</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>&gt;70</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.720380</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.912461</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.005810</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>&gt;70</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.114501</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.253185</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.154975</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 55 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f76cae7d-0f4e-4b5f-952a-72ef67d1c16e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f76cae7d-0f4e-4b5f-952a-72ef67d1c16e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f76cae7d-0f4e-4b5f-952a-72ef67d1c16e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTDaLBWF_mf5",
        "outputId": "a2a6cfe5-1e8e-4d65-911b-20f3ee07b395"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4711, 55)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.drop(4710)"
      ],
      "metadata": {
        "id": "gzrl4F2tzhT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWXamZdyzkaq",
        "outputId": "efb8f694-5d2d-45cc-dcbe-45debb24cf53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4710, 55)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "req_features=['LOS_Y', 'LOS', 'Severity',\n",
        "       'All CNS', 'Pure CNS', 'Age.1', 'AgeScore', 'O2 Sat < 94', 'MAP < 70', 'Ddimer', 'D-Dimer > 3', 'PltsScore', 'INRYes', 'INR', 'INR > 1.2', 'BUN',\n",
        "       'BUN > 30', 'Creatinine', 'CrtnScore',\n",
        "       'Sodium < 139 or > 154', 'AST', 'AST > 40', 'WBC', 'WBC <1.8 or > 4.8',\n",
        "       'Lymphocytes < 1', 'IL6 > 150',\n",
        "       'Ferritin', 'Ferritin > 300', 'CrctProtein',\n",
        "       'C-Reactive Prot > 10', 'Procalcitonin',\n",
        "       'Procalciton > 0.1', 'TropYes', 'Troponin', 'Troponin > 0.1']"
      ],
      "metadata": {
        "id": "YiEV049g_6_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=df[req_features]"
      ],
      "metadata": {
        "id": "r1eqFGw5ztIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIXzhisSMJ2y",
        "outputId": "ed0e7d25-0ef2-442e-ebea-4987ff3969f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4710, 35)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y=df['Death']"
      ],
      "metadata": {
        "id": "qUpOfJyuzvTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, Y, test_size=0.2, random_state=2)\n",
        "print(X_train1.shape)\n",
        "print(y_train1.shape)\n",
        "print(X_test1.shape)\n",
        "print(y_test1.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ETQAxRdAlUT",
        "outputId": "e16c8771-be0a-49b7-fa3c-aaf7f6c1f79c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3768, 35)\n",
            "(3768,)\n",
            "(942, 35)\n",
            "(942,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv1D(filters=256, kernel_size=3, strides=1, activation='relu', input_shape=(35,1)))\n",
        "model.add(MaxPooling1D(pool_size=2 ,strides=1))\n",
        "#model.add(Conv1D(filters=256, kernel_size=3, strides=1, activation='relu'))\n",
        "#model.add(Conv1D(filters=512, kernel_size=3, strides=1, activation='relu'))\n",
        "model.add(Conv1D(filters=256, kernel_size=3, strides=1, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2 ,strides=1))\n",
        "model.add(Conv1D(filters=256, kernel_size=3, strides=1, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2 ,strides=1))\n",
        "#model.add(Conv1D(filters=256, kernel_size=3, strides=1, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2 ,strides=1))\n",
        "#model.add(Reshape((64,32,3), input_shape=(24,256)))\n",
        "#model.add(Reshape((11,340,3), input_shape=(11,4,256)))\n",
        "#model.add(VGG19(include_top=False,weights=\"imagenet\",input_shape=(64,32,3)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jUUwNzZ-jSp",
        "outputId": "6a1396be-3529-4589-a952-20de8ba0aa8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 33, 256)           1024      \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 32, 256)          0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 30, 256)           196864    \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 29, 256)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 27, 256)           196864    \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPooling  (None, 26, 256)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " max_pooling1d_3 (MaxPooling  (None, 25, 256)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 6400)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                409664    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 806,529\n",
            "Trainable params: 806,529\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.optimizers import SGD, Adam, Adamax, Adadelta\n",
        "import sklearn\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "48xDd4WsBLex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt=Adam(learning_rate= 0.0001)  "
      ],
      "metadata": {
        "id": "fMTc0GRSBYIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "METRICS = [\n",
        "      keras.metrics.TruePositives(name='tp'),\n",
        "      keras.metrics.FalsePositives(name='fp'),\n",
        "      keras.metrics.TrueNegatives(name='tn'),\n",
        "      keras.metrics.FalseNegatives(name='fn'), \n",
        "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      keras.metrics.Precision(name='Precision'),\n",
        "      keras.metrics.Recall(name='Recall'),\n",
        "      keras.metrics.AUC(name='Auc'),\n",
        "      \n",
        "]"
      ],
      "metadata": {
        "id": "Ys4O0B9wRttM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer= opt,\n",
        "              metrics='accuracy')"
      ],
      "metadata": {
        "id": "zUFmPcCjB0ZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import classification_report\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score, f1_score, recall_score, roc_auc_score, confusion_matrix"
      ],
      "metadata": {
        "id": "ApVkAzevB1sr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = KFold(n_splits=10, shuffle=False)"
      ],
      "metadata": {
        "id": "UKQzZnJHR1qi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "j=1           \n",
        "i=1\n",
        "for train_index, test_index in kfold.split(df):\n",
        "    X4 = df.iloc[train_index].loc[:, req_features]\n",
        "    X5 = df.iloc[test_index][req_features]\n",
        "    y4= df.iloc[train_index].loc[:,'Death']\n",
        "    y5 = df.iloc[test_index]['Death']\n",
        "\n",
        "    X6= X4.to_numpy('float64')\n",
        "    X7=np.resize(X6,(4239,35,1))\n",
        "    X8= X5.to_numpy('float64')\n",
        "    X9=np.resize(X8,(471,35,1))\n",
        "    y6=y4.to_numpy('int')    #train output\n",
        "    y7=y5.to_numpy('int')\n",
        "    train_x = X7\n",
        "    train_y = y6\n",
        "    validation_x = X9\n",
        "    validation_y = y7\n",
        "    history= model.fit(train_x , train_y, epochs=10, batch_size=12,verbose=1) #Training the model\n",
        "    ypre=model.predict(validation_x)\n",
        "    pre_y=np.round(abs(ypre))\n",
        "    print(f\"Accuracy for the fold no. {i} on the test set: {accuracy_score(validation_y, pre_y )}\")\n",
        "    accuracy = accuracy_score(validation_y, pre_y)\n",
        "    print('Accuracy: %f' % accuracy)\n",
        "    matrix = confusion_matrix(validation_y, pre_y)\n",
        "    print(matrix)\n",
        "    i+= 1 \n",
        "    j=j+1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwA32qK3SBq6",
        "outputId": "4ae26ba5-05fc-4a2c-e65a-02f7fe453ca3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "354/354 [==============================] - 15s 9ms/step - loss: 0.5405 - accuracy: 0.7570\n",
            "Epoch 2/10\n",
            "354/354 [==============================] - 3s 7ms/step - loss: 0.5022 - accuracy: 0.7636\n",
            "Epoch 3/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.4687 - accuracy: 0.7716\n",
            "Epoch 4/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.4508 - accuracy: 0.7886\n",
            "Epoch 5/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.4348 - accuracy: 0.7981\n",
            "Epoch 6/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.4307 - accuracy: 0.8035\n",
            "Epoch 7/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.4161 - accuracy: 0.8143\n",
            "Epoch 8/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.4154 - accuracy: 0.8092\n",
            "Epoch 9/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.4083 - accuracy: 0.8162\n",
            "Epoch 10/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.4120 - accuracy: 0.8160\n",
            "Accuracy for the fold no. 1 on the test set: 0.8131634819532909\n",
            "Accuracy: 0.813163\n",
            "[[301  46]\n",
            " [ 42  82]]\n",
            "Epoch 1/10\n",
            "354/354 [==============================] - 3s 7ms/step - loss: 0.4039 - accuracy: 0.8221\n",
            "Epoch 2/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.3998 - accuracy: 0.8266\n",
            "Epoch 3/10\n",
            "354/354 [==============================] - 3s 7ms/step - loss: 0.3955 - accuracy: 0.8243\n",
            "Epoch 4/10\n",
            "354/354 [==============================] - 3s 7ms/step - loss: 0.3888 - accuracy: 0.8276\n",
            "Epoch 5/10\n",
            "354/354 [==============================] - 3s 7ms/step - loss: 0.3882 - accuracy: 0.8261\n",
            "Epoch 6/10\n",
            "354/354 [==============================] - 3s 7ms/step - loss: 0.3852 - accuracy: 0.8306\n",
            "Epoch 7/10\n",
            "354/354 [==============================] - 3s 7ms/step - loss: 0.3824 - accuracy: 0.8311\n",
            "Epoch 8/10\n",
            "354/354 [==============================] - 3s 7ms/step - loss: 0.3823 - accuracy: 0.8344\n",
            "Epoch 9/10\n",
            "354/354 [==============================] - 3s 7ms/step - loss: 0.3757 - accuracy: 0.8375\n",
            "Epoch 10/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.3758 - accuracy: 0.8365\n",
            "Accuracy for the fold no. 2 on the test set: 0.8046709129511678\n",
            "Accuracy: 0.804671\n",
            "[[328  15]\n",
            " [ 77  51]]\n",
            "Epoch 1/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.3805 - accuracy: 0.8353\n",
            "Epoch 2/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.3757 - accuracy: 0.8372\n",
            "Epoch 3/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.3724 - accuracy: 0.8363\n",
            "Epoch 4/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.3650 - accuracy: 0.8391\n",
            "Epoch 5/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.3649 - accuracy: 0.8396\n",
            "Epoch 6/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.3631 - accuracy: 0.8408\n",
            "Epoch 7/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.3600 - accuracy: 0.8462\n",
            "Epoch 8/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.3586 - accuracy: 0.8457\n",
            "Epoch 9/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.3490 - accuracy: 0.8476\n",
            "Epoch 10/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.3485 - accuracy: 0.8481\n",
            "Accuracy for the fold no. 3 on the test set: 0.861995753715499\n",
            "Accuracy: 0.861996\n",
            "[[334   9]\n",
            " [ 56  72]]\n",
            "Epoch 1/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.3545 - accuracy: 0.8434\n",
            "Epoch 2/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.3521 - accuracy: 0.8462\n",
            "Epoch 3/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.3436 - accuracy: 0.8519\n",
            "Epoch 4/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.3410 - accuracy: 0.8559\n",
            "Epoch 5/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.3403 - accuracy: 0.8514\n",
            "Epoch 6/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.3365 - accuracy: 0.8521\n",
            "Epoch 7/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.3335 - accuracy: 0.8521\n",
            "Epoch 8/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.3298 - accuracy: 0.8596\n",
            "Epoch 9/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.3206 - accuracy: 0.8618\n",
            "Epoch 10/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.3219 - accuracy: 0.8641\n",
            "Accuracy for the fold no. 4 on the test set: 0.8577494692144374\n",
            "Accuracy: 0.857749\n",
            "[[345   1]\n",
            " [ 66  59]]\n",
            "Epoch 1/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.3274 - accuracy: 0.8620\n",
            "Epoch 2/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.3165 - accuracy: 0.8599\n",
            "Epoch 3/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.3098 - accuracy: 0.8686\n",
            "Epoch 4/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.3079 - accuracy: 0.8712\n",
            "Epoch 5/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.3054 - accuracy: 0.8700\n",
            "Epoch 6/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.2958 - accuracy: 0.8773\n",
            "Epoch 7/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.2956 - accuracy: 0.8717\n",
            "Epoch 8/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.2902 - accuracy: 0.8778\n",
            "Epoch 9/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.2825 - accuracy: 0.8851\n",
            "Epoch 10/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.2844 - accuracy: 0.8835\n",
            "Accuracy for the fold no. 5 on the test set: 0.8789808917197452\n",
            "Accuracy: 0.878981\n",
            "[[333  22]\n",
            " [ 35  81]]\n",
            "Epoch 1/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.2848 - accuracy: 0.8790\n",
            "Epoch 2/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.2743 - accuracy: 0.8851\n",
            "Epoch 3/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.2700 - accuracy: 0.8868\n",
            "Epoch 4/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.2623 - accuracy: 0.8910\n",
            "Epoch 5/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.2549 - accuracy: 0.8990\n",
            "Epoch 6/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.2560 - accuracy: 0.8988\n",
            "Epoch 7/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.2449 - accuracy: 0.8957\n",
            "Epoch 8/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.2381 - accuracy: 0.9000\n",
            "Epoch 9/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.2372 - accuracy: 0.9040\n",
            "Epoch 10/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.2329 - accuracy: 0.9023\n",
            "Accuracy for the fold no. 6 on the test set: 0.8789808917197452\n",
            "Accuracy: 0.878981\n",
            "[[336  14]\n",
            " [ 43  78]]\n",
            "Epoch 1/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.2429 - accuracy: 0.8971\n",
            "Epoch 2/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.2268 - accuracy: 0.9066\n",
            "Epoch 3/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.2207 - accuracy: 0.9127\n",
            "Epoch 4/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.2174 - accuracy: 0.9120\n",
            "Epoch 5/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.2096 - accuracy: 0.9165\n",
            "Epoch 6/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.2059 - accuracy: 0.9193\n",
            "Epoch 7/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.2002 - accuracy: 0.9188\n",
            "Epoch 8/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.1918 - accuracy: 0.9222\n",
            "Epoch 9/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.1919 - accuracy: 0.9222\n",
            "Epoch 10/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.1884 - accuracy: 0.9297\n",
            "Accuracy for the fold no. 7 on the test set: 0.8853503184713376\n",
            "Accuracy: 0.885350\n",
            "[[330  26]\n",
            " [ 28  87]]\n",
            "Epoch 1/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.1908 - accuracy: 0.9247\n",
            "Epoch 2/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.1842 - accuracy: 0.9269\n",
            "Epoch 3/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.1744 - accuracy: 0.9339\n",
            "Epoch 4/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.1695 - accuracy: 0.9344\n",
            "Epoch 5/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.1670 - accuracy: 0.9335\n",
            "Epoch 6/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.1623 - accuracy: 0.9377\n",
            "Epoch 7/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.1531 - accuracy: 0.9398\n",
            "Epoch 8/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.1521 - accuracy: 0.9436\n",
            "Epoch 9/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.1533 - accuracy: 0.9441\n",
            "Epoch 10/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.1465 - accuracy: 0.9472\n",
            "Accuracy for the fold no. 8 on the test set: 0.921443736730361\n",
            "Accuracy: 0.921444\n",
            "[[357   8]\n",
            " [ 29  77]]\n",
            "Epoch 1/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.1414 - accuracy: 0.9434\n",
            "Epoch 2/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.1342 - accuracy: 0.9502\n",
            "Epoch 3/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.1279 - accuracy: 0.9528\n",
            "Epoch 4/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.1241 - accuracy: 0.9545\n",
            "Epoch 5/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.1278 - accuracy: 0.9509\n",
            "Epoch 6/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.1190 - accuracy: 0.9521\n",
            "Epoch 7/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.1128 - accuracy: 0.9573\n",
            "Epoch 8/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.1140 - accuracy: 0.9571\n",
            "Epoch 9/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.1061 - accuracy: 0.9646\n",
            "Epoch 10/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.1033 - accuracy: 0.9627\n",
            "Accuracy for the fold no. 9 on the test set: 0.9044585987261147\n",
            "Accuracy: 0.904459\n",
            "[[363   8]\n",
            " [ 37  63]]\n",
            "Epoch 1/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.1078 - accuracy: 0.9630\n",
            "Epoch 2/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.1147 - accuracy: 0.9606\n",
            "Epoch 3/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.1048 - accuracy: 0.9644\n",
            "Epoch 4/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.0886 - accuracy: 0.9693\n",
            "Epoch 5/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.0881 - accuracy: 0.9689\n",
            "Epoch 6/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.0838 - accuracy: 0.9741\n",
            "Epoch 7/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.0847 - accuracy: 0.9705\n",
            "Epoch 8/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.0957 - accuracy: 0.9665\n",
            "Epoch 9/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.0845 - accuracy: 0.9689\n",
            "Epoch 10/10\n",
            "354/354 [==============================] - 3s 8ms/step - loss: 0.0810 - accuracy: 0.9707\n",
            "Accuracy for the fold no. 10 on the test set: 0.8959660297239915\n",
            "Accuracy: 0.895966\n",
            "[[373  13]\n",
            " [ 36  49]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test2=np.resize(X_test1,(942,35,1))   #validation data  \n",
        "y_test2=y_test1.to_numpy('int')    #train output\n",
        "validation_x = X_test2\n",
        "validation_y = y_test2\n",
        "ypre=model.predict(validation_x)\n",
        "pre_y=np.where(ypre>0.5, 1, 0)\n",
        "accuracy = accuracy_score(validation_y, pre_y)\n",
        "auc=metrics.roc_auc_score(validation_y, pre_y)\n",
        "print('Accuracy: %f' % accuracy)\n",
        "print('AUC: %f' % auc)\n",
        "print('Classification Report')\n",
        "target_names = ['Recovered', 'Died']\n",
        "print(classification_report(validation_y, pre_y, target_names=target_names))\n",
        "# confusion matrix\n",
        "matrix = confusion_matrix(validation_y, pre_y)\n",
        "print(matrix)\n",
        "ax=plt.subplot()\n",
        "sns.heatmap(matrix,annot=True,ax=ax,cmap='OrRd_r', fmt='g')#annot=True to annotate cells, fmt='g' numbers not scientific form\n",
        "ax.set_xlabel('Predicted labels'); \n",
        "ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix'); \n",
        "ax.xaxis.set_ticklabels(['Died', 'recovered']); \n",
        "ax.yaxis.set_ticklabels(['Died', 'recovered']);\n",
        "ax.set(yticks=[0, 2], \n",
        "       xticks=[0.5, 1.5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "mk4xmdNVlC9w",
        "outputId": "3e863575-5309-4691-a437-003b23bf8e89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.977707\n",
            "AUC: 0.956020\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Recovered       0.98      0.99      0.99       736\n",
            "        Died       0.98      0.92      0.95       206\n",
            "\n",
            "    accuracy                           0.98       942\n",
            "   macro avg       0.98      0.96      0.97       942\n",
            "weighted avg       0.98      0.98      0.98       942\n",
            "\n",
            "[[732   4]\n",
            " [ 17 189]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[<matplotlib.axis.YTick at 0x7fed44ddb290>,\n",
              "  <matplotlib.axis.YTick at 0x7fed44ddb810>],\n",
              " [<matplotlib.axis.XTick at 0x7fed44e1e110>,\n",
              "  <matplotlib.axis.XTick at 0x7fed44e1eb10>]]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "precision, recall, thresholds = precision_recall_curve(validation_y,pre_y)\n",
        "plt.plot(precision,recall)\n",
        "plt.ylabel('Recall')\n",
        "plt.xlabel('Precision')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "63xgJyULxOow",
        "outputId": "07de44b1-9137-4c11-9e15-586e0f57110b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}