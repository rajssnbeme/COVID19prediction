{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "whrVagVehwQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPOhEunFmHk9",
        "outputId": "31d3c618-3638-42d2-ed80-36e1ffbf1bc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D,Conv1D\n",
        "from keras.layers import MaxPooling1D,MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import AveragePooling1D,AveragePooling2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers import Dropout\n",
        "from keras import regularizers\n",
        "from tensorflow.keras.optimizers import SGD, Adam, Adamax, Adadelta\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score, f1_score, recall_score, roc_auc_score, confusion_matrix"
      ],
      "metadata": {
        "id": "VFn3J28Um19h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/gdrive/MyDrive/Risk Prediction/Dataset/SMOTEdata.csv',index_col=[0])"
      ],
      "metadata": {
        "id": "LsSx8-jNm9WH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "2K52TKNLzGj8",
        "outputId": "d23475ce-3d31-4b52-cd59-f173b2de508a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Derivation cohort  LOS_Y  LOS  Severity  Black  White  Asian  Latino  MI  \\\n",
              "0                  1      1    1         3      0      0      0       0   0   \n",
              "1                  1      1    2         7      0      1      0       0   0   \n",
              "2                  1      1    2         7      0      1      0       0   0   \n",
              "3                  1      1   15         9      1      0      0       0   1   \n",
              "4                  1      1    9         7      1      0      0       0   0   \n",
              "\n",
              "        PVD  ...  CrctProtein  C-Reactive Prot > 10  ProCalCYes  \\\n",
              "0 -0.372374  ...    -0.961308                     0           0   \n",
              "1  2.471715  ...     0.291863                     1           1   \n",
              "2  2.471715  ...     1.945341                     1           1   \n",
              "3 -0.372374  ...     0.596451                     1           1   \n",
              "4 -0.372374  ...     0.004680                     1           0   \n",
              "\n",
              "   Procalcitonin  Procalciton > 0.1  TropYes  Troponin  Troponin > 0.1  Death  \\\n",
              "0      -0.312628                  0        1 -0.175698               0      0   \n",
              "1      -0.223443                  1        1  3.692703               1      1   \n",
              "2      -0.134259                  1        0 -0.208205               0      1   \n",
              "3       0.772450                  1        1 -0.045667               0      0   \n",
              "4      -0.312628                  0        1 -0.175698               0      0   \n",
              "\n",
              "   Severity_class  \n",
              "0               1  \n",
              "1               2  \n",
              "2               2  \n",
              "3               3  \n",
              "4               2  \n",
              "\n",
              "[5 rows x 85 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-82c00bca-ad3d-4785-b58c-110d009a24f0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Derivation cohort</th>\n",
              "      <th>LOS_Y</th>\n",
              "      <th>LOS</th>\n",
              "      <th>Severity</th>\n",
              "      <th>Black</th>\n",
              "      <th>White</th>\n",
              "      <th>Asian</th>\n",
              "      <th>Latino</th>\n",
              "      <th>MI</th>\n",
              "      <th>PVD</th>\n",
              "      <th>...</th>\n",
              "      <th>CrctProtein</th>\n",
              "      <th>C-Reactive Prot &gt; 10</th>\n",
              "      <th>ProCalCYes</th>\n",
              "      <th>Procalcitonin</th>\n",
              "      <th>Procalciton &gt; 0.1</th>\n",
              "      <th>TropYes</th>\n",
              "      <th>Troponin</th>\n",
              "      <th>Troponin &gt; 0.1</th>\n",
              "      <th>Death</th>\n",
              "      <th>Severity_class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.372374</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.961308</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.312628</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.175698</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.471715</td>\n",
              "      <td>...</td>\n",
              "      <td>0.291863</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.223443</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3.692703</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.471715</td>\n",
              "      <td>...</td>\n",
              "      <td>1.945341</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.134259</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.208205</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.372374</td>\n",
              "      <td>...</td>\n",
              "      <td>0.596451</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.772450</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.045667</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.372374</td>\n",
              "      <td>...</td>\n",
              "      <td>0.004680</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.312628</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.175698</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 85 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-82c00bca-ad3d-4785-b58c-110d009a24f0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-82c00bca-ad3d-4785-b58c-110d009a24f0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-82c00bca-ad3d-4785-b58c-110d009a24f0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "-otKsJoIwz3v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "270815a1-b448-4118-eaec-3f3aeb310802"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7126, 85)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "req_features=['LOS_Y', 'LOS', 'Severity',\n",
        "       'All CNS', 'Pure CNS', 'Age.1', 'AgeScore', 'O2 Sat < 94', 'MAP < 70', 'Ddimer', 'D-Dimer > 3', 'PltsScore', 'INRYes', 'INR', 'INR > 1.2', 'BUN',\n",
        "       'BUN > 30', 'Creatinine', 'CrtnScore',\n",
        "       'Sodium < 139 or > 154', 'AST', 'AST > 40', 'WBC', 'WBC <1.8 or > 4.8',\n",
        "       'Lymphocytes < 1', 'IL6 > 150',\n",
        "       'Ferritin', 'Ferritin > 300', 'CrctProtein',\n",
        "       'C-Reactive Prot > 10', 'Procalcitonin',\n",
        "       'Procalciton > 0.1', 'TropYes', 'Troponin', 'Troponin > 0.1']"
      ],
      "metadata": {
        "id": "a5PQ-Ddsw8V_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=df[req_features]"
      ],
      "metadata": {
        "id": "s8yjXVVCw_03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y=df['Death']"
      ],
      "metadata": {
        "id": "ByW9q14cxCz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, Y, test_size=0.2, random_state=2)\n",
        "print(X_train1.shape)\n",
        "print(y_train1.shape)\n",
        "print(X_test1.shape)\n",
        "print(y_test1.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqcAmTk4TIVr",
        "outputId": "cfe1d52c-172a-4d65-98e5-c8bfab4b026c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5700, 35)\n",
            "(5700,)\n",
            "(1426, 35)\n",
            "(1426,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "#model.add(BatchNormalization(input_shape=(35,1)))\n",
        "model.add(Reshape((7,5,1), input_shape=(35,1)))\n",
        "print(\"shape is {}\".format(model.output_shape))\n",
        "model.add(TimeDistributed(LSTM(256, activation='tanh',return_sequences = True)))\n",
        "model.add(Dropout(0.6))\n",
        "#model.add(BatchNormalization())\n",
        "model.add(TimeDistributed(Conv1D(256, kernel_size=4, activation='relu', \n",
        "                                 padding=\"same\",\n",
        "                                 kernel_regularizer=regularizers.l2(0.01), \n",
        "                                 bias_regularizer=regularizers.l2(0.01))))\n",
        "model.add(Conv1D(filters=256, kernel_size=3, strides=1, activation='relu'))\n",
        "model.add(AveragePooling2D((2,2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(units=128, activation='relu'))\n",
        "model.add(Dense(units=64, activation='relu'))\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "EyfoWWAExERG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d266650b-8980-4585-8008-676f798fa2d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape is (None, 7, 5, 1)\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape (Reshape)           (None, 7, 5, 1)           0         \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 7, 5, 256)        264192    \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 7, 5, 256)         0         \n",
            "                                                                 \n",
            " time_distributed_1 (TimeDis  (None, 7, 5, 256)        262400    \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 7, 3, 256)         196864    \n",
            "                                                                 \n",
            " average_pooling2d (AverageP  (None, 3, 1, 256)        0         \n",
            " ooling2D)                                                       \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 768)               0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 768)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               98432     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 830,209\n",
            "Trainable params: 830,209\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opt=Adam(learning_rate= 0.0001)"
      ],
      "metadata": {
        "id": "q4wJoc2x3YvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer= opt,\n",
        "              metrics='accuracy')"
      ],
      "metadata": {
        "id": "VqcYzra_xZlv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = KFold(n_splits=10, shuffle=False)"
      ],
      "metadata": {
        "id": "IRMZ6XQ9xfJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "j=1           \n",
        "i=1\n",
        "for train_index, test_index in kfold.split(df):\n",
        "    X4 = df.iloc[train_index].loc[:, req_features]\n",
        "    X5 = df.iloc[test_index][req_features]\n",
        "    y4= df.iloc[train_index].loc[:,'Death']\n",
        "    y5 = df.loc[test_index]['Death']\n",
        "\n",
        "    X6= X4.to_numpy('float64')\n",
        "    X7=np.resize(X6,(X4.shape[0],35,1))\n",
        "    X8= X5.to_numpy('float64')\n",
        "    X9=np.resize(X8,(X5.shape[0],35,1))\n",
        "    y6=y4.to_numpy('int')    #train output\n",
        "    y7=y5.to_numpy('int')\n",
        "    train_x = X7\n",
        "    train_y = y6\n",
        "    validation_x = X9\n",
        "    validation_y = y7\n",
        "    history= model.fit(train_x , train_y, epochs=10, batch_size=12,verbose=1) #Training the model\n",
        "    ypre=model.predict(validation_x)\n",
        "    pre_y=np.round(abs(ypre))\n",
        "    print(f\"Accuracy for the fold no. {i} on the test set: {accuracy_score(validation_y, pre_y )}\")\n",
        "    accuracy = accuracy_score(validation_y, pre_y)\n",
        "    print('Accuracy: %f' % accuracy)\n",
        "    matrix = confusion_matrix(validation_y, pre_y)\n",
        "    print(matrix)\n",
        "    i+= 1 \n",
        "    j=j+1"
      ],
      "metadata": {
        "id": "V6e9VYg1xvT_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59693434-bc27-4868-b65a-55f780feb2f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "535/535 [==============================] - 17s 6ms/step - loss: 1.5716 - accuracy: 0.6099\n",
            "Epoch 2/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.7112 - accuracy: 0.6923\n",
            "Epoch 3/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.6156 - accuracy: 0.7137\n",
            "Epoch 4/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.5922 - accuracy: 0.7118\n",
            "Epoch 5/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.5713 - accuracy: 0.7249\n",
            "Epoch 6/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.5629 - accuracy: 0.7221\n",
            "Epoch 7/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.5493 - accuracy: 0.7288\n",
            "Epoch 8/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.5411 - accuracy: 0.7348\n",
            "Epoch 9/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.5244 - accuracy: 0.7421\n",
            "Epoch 10/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.5177 - accuracy: 0.7410\n",
            "Accuracy for the fold no. 1 on the test set: 0.6549789621318373\n",
            "Accuracy: 0.654979\n",
            "[[309 209]\n",
            " [ 37 158]]\n",
            "Epoch 1/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.5058 - accuracy: 0.7494\n",
            "Epoch 2/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.5078 - accuracy: 0.7508\n",
            "Epoch 3/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.4953 - accuracy: 0.7592\n",
            "Epoch 4/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.4923 - accuracy: 0.7563\n",
            "Epoch 5/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.4837 - accuracy: 0.7702\n",
            "Epoch 6/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.4807 - accuracy: 0.7663\n",
            "Epoch 7/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.4717 - accuracy: 0.7801\n",
            "Epoch 8/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.4747 - accuracy: 0.7734\n",
            "Epoch 9/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.4692 - accuracy: 0.7786\n",
            "Epoch 10/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.4640 - accuracy: 0.7809\n",
            "Accuracy for the fold no. 2 on the test set: 0.7629733520336606\n",
            "Accuracy: 0.762973\n",
            "[[444  81]\n",
            " [ 88 100]]\n",
            "Epoch 1/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.4586 - accuracy: 0.7864\n",
            "Epoch 2/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.4600 - accuracy: 0.7817\n",
            "Epoch 3/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.4589 - accuracy: 0.7837\n",
            "Epoch 4/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.4544 - accuracy: 0.7870\n",
            "Epoch 5/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.4503 - accuracy: 0.7918\n",
            "Epoch 6/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.4494 - accuracy: 0.7903\n",
            "Epoch 7/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.4440 - accuracy: 0.7934\n",
            "Epoch 8/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.4493 - accuracy: 0.7887\n",
            "Epoch 9/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.4369 - accuracy: 0.7971\n",
            "Epoch 10/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.4413 - accuracy: 0.7968\n",
            "Accuracy for the fold no. 3 on the test set: 0.7685834502103787\n",
            "Accuracy: 0.768583\n",
            "[[404 121]\n",
            " [ 44 144]]\n",
            "Epoch 1/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.4387 - accuracy: 0.7965\n",
            "Epoch 2/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.4372 - accuracy: 0.7988\n",
            "Epoch 3/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.4353 - accuracy: 0.7960\n",
            "Epoch 4/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.4321 - accuracy: 0.7939\n",
            "Epoch 5/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.4285 - accuracy: 0.8052\n",
            "Epoch 6/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.4253 - accuracy: 0.8043\n",
            "Epoch 7/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.4251 - accuracy: 0.8065\n",
            "Epoch 8/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.4215 - accuracy: 0.8059\n",
            "Epoch 9/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.4179 - accuracy: 0.8049\n",
            "Epoch 10/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.4249 - accuracy: 0.8066\n",
            "Accuracy for the fold no. 4 on the test set: 0.7854137447405329\n",
            "Accuracy: 0.785414\n",
            "[[442  90]\n",
            " [ 63 118]]\n",
            "Epoch 1/10\n",
            "535/535 [==============================] - 4s 8ms/step - loss: 0.4300 - accuracy: 0.8017\n",
            "Epoch 2/10\n",
            "535/535 [==============================] - 4s 8ms/step - loss: 0.4196 - accuracy: 0.8085\n",
            "Epoch 3/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.4222 - accuracy: 0.8079\n",
            "Epoch 4/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.4113 - accuracy: 0.8130\n",
            "Epoch 5/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.4166 - accuracy: 0.8101\n",
            "Epoch 6/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.4112 - accuracy: 0.8183\n",
            "Epoch 7/10\n",
            "535/535 [==============================] - 4s 8ms/step - loss: 0.4161 - accuracy: 0.8088\n",
            "Epoch 8/10\n",
            "535/535 [==============================] - 4s 8ms/step - loss: 0.4177 - accuracy: 0.8094\n",
            "Epoch 9/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.4087 - accuracy: 0.8166\n",
            "Epoch 10/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.4142 - accuracy: 0.8129\n",
            "Accuracy for the fold no. 5 on the test set: 0.8246844319775596\n",
            "Accuracy: 0.824684\n",
            "[[479  72]\n",
            " [ 53 109]]\n",
            "Epoch 1/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.3942 - accuracy: 0.8269\n",
            "Epoch 2/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.3942 - accuracy: 0.8232\n",
            "Epoch 3/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.3937 - accuracy: 0.8243\n",
            "Epoch 4/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.3932 - accuracy: 0.8213\n",
            "Epoch 5/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.3940 - accuracy: 0.8188\n",
            "Epoch 6/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.3897 - accuracy: 0.8252\n",
            "Epoch 7/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.3880 - accuracy: 0.8268\n",
            "Epoch 8/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.3863 - accuracy: 0.8282\n",
            "Epoch 9/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.3920 - accuracy: 0.8230\n",
            "Epoch 10/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.3901 - accuracy: 0.8246\n",
            "Accuracy for the fold no. 6 on the test set: 0.7517531556802244\n",
            "Accuracy: 0.751753\n",
            "[[437 121]\n",
            " [ 56  99]]\n",
            "Epoch 1/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.3939 - accuracy: 0.8260\n",
            "Epoch 2/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.3908 - accuracy: 0.8273\n",
            "Epoch 3/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.3890 - accuracy: 0.8252\n",
            "Epoch 4/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.3888 - accuracy: 0.8263\n",
            "Epoch 5/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.3889 - accuracy: 0.8293\n",
            "Epoch 6/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.3856 - accuracy: 0.8285\n",
            "Epoch 7/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.3884 - accuracy: 0.8282\n",
            "Epoch 8/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.3825 - accuracy: 0.8283\n",
            "Epoch 9/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.3832 - accuracy: 0.8302\n",
            "Epoch 10/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.3801 - accuracy: 0.8312\n",
            "Accuracy for the fold no. 7 on the test set: 0.7851123595505618\n",
            "Accuracy: 0.785112\n",
            "[[290  64]\n",
            " [ 89 269]]\n",
            "Epoch 1/10\n",
            "535/535 [==============================] - 4s 7ms/step - loss: 0.4018 - accuracy: 0.8282\n",
            "Epoch 2/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.4008 - accuracy: 0.8268\n",
            "Epoch 3/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.4014 - accuracy: 0.8230\n",
            "Epoch 4/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.3968 - accuracy: 0.8257\n",
            "Epoch 5/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.4006 - accuracy: 0.8210\n",
            "Epoch 6/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.3955 - accuracy: 0.8248\n",
            "Epoch 7/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.4014 - accuracy: 0.8235\n",
            "Epoch 8/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.3958 - accuracy: 0.8237\n",
            "Epoch 9/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.3889 - accuracy: 0.8316\n",
            "Epoch 10/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.3934 - accuracy: 0.8263\n",
            "Accuracy for the fold no. 8 on the test set: 0.8441011235955056\n",
            "Accuracy: 0.844101\n",
            "[[  0   0]\n",
            " [111 601]]\n",
            "Epoch 1/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.3993 - accuracy: 0.8215\n",
            "Epoch 2/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.4020 - accuracy: 0.8237\n",
            "Epoch 3/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.3981 - accuracy: 0.8285\n",
            "Epoch 4/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.3944 - accuracy: 0.8232\n",
            "Epoch 5/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.3975 - accuracy: 0.8210\n",
            "Epoch 6/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.3955 - accuracy: 0.8248\n",
            "Epoch 7/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.3928 - accuracy: 0.8274\n",
            "Epoch 8/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.3979 - accuracy: 0.8229\n",
            "Epoch 9/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.3906 - accuracy: 0.8316\n",
            "Epoch 10/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.3928 - accuracy: 0.8274\n",
            "Accuracy for the fold no. 9 on the test set: 0.9311797752808989\n",
            "Accuracy: 0.931180\n",
            "[[  0   0]\n",
            " [ 49 663]]\n",
            "Epoch 1/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.3945 - accuracy: 0.8280\n",
            "Epoch 2/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.3897 - accuracy: 0.8341\n",
            "Epoch 3/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.3926 - accuracy: 0.8262\n",
            "Epoch 4/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.3856 - accuracy: 0.8268\n",
            "Epoch 5/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.3912 - accuracy: 0.8352\n",
            "Epoch 6/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.3889 - accuracy: 0.8330\n",
            "Epoch 7/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.3874 - accuracy: 0.8338\n",
            "Epoch 8/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.3895 - accuracy: 0.8310\n",
            "Epoch 9/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.3838 - accuracy: 0.8347\n",
            "Epoch 10/10\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.3880 - accuracy: 0.8335\n",
            "Accuracy for the fold no. 10 on the test set: 0.8932584269662921\n",
            "Accuracy: 0.893258\n",
            "[[  0   0]\n",
            " [ 76 636]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "DJhwmO7-ig8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test2=np.resize(X_test1,(1426,35,1))   #validation data  \n",
        "y_test2=y_test1.to_numpy('int')    #train output\n",
        "validation_x = X_test2\n",
        "validation_y = y_test2\n",
        "ypre=model.predict(validation_x)\n",
        "pre_y=np.where(ypre>0.5, 1, 0)\n",
        "accuracy = accuracy_score(validation_y, pre_y)\n",
        "auc=metrics.roc_auc_score(validation_y, pre_y)\n",
        "print('Accuracy: %f' % accuracy)\n",
        "print('AUC: %f' % auc)\n",
        "print('Classification Report')\n",
        "target_names = ['Recovered', 'Died']\n",
        "print(classification_report(validation_y, pre_y, target_names=target_names))\n",
        "# confusion matrix\n",
        "matrix = confusion_matrix(validation_y, pre_y)\n",
        "print(matrix)\n",
        "ax=plt.subplot()\n",
        "sns.heatmap(matrix,annot=True,ax=ax,cmap='OrRd_r', fmt='g')#annot=True to annotate cells, fmt='g' numbers not scientific form\n",
        "ax.set_xlabel('Predicted labels'); \n",
        "ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix'); \n",
        "ax.xaxis.set_ticklabels(['Died', 'recovered']); \n",
        "ax.yaxis.set_ticklabels(['Died', 'recovered']);\n",
        "ax.set(yticks=[0, 2], \n",
        "       xticks=[0.5, 1.5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "BoAThDJYgUE7",
        "outputId": "d5ef2612-94c4-4cb4-f6e6-cb96c5c31432"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.867461\n",
            "AUC: 0.866113\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Recovered       0.82      0.95      0.88       725\n",
            "        Died       0.93      0.79      0.85       701\n",
            "\n",
            "    accuracy                           0.87      1426\n",
            "   macro avg       0.88      0.87      0.87      1426\n",
            "weighted avg       0.88      0.87      0.87      1426\n",
            "\n",
            "[[686  39]\n",
            " [150 551]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[<matplotlib.axis.YTick at 0x7ff6a0e10f10>,\n",
              "  <matplotlib.axis.YTick at 0x7ff6a1640210>],\n",
              " [<matplotlib.axis.XTick at 0x7ff6a163e610>,\n",
              "  <matplotlib.axis.XTick at 0x7ff6a0e143d0>]]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "precision, recall, thresholds = precision_recall_curve(validation_y,pre_y)\n",
        "plt.plot(precision,recall)\n",
        "plt.ylabel('Recall')\n",
        "plt.xlabel('Precision')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "WiUBRQMlxNqO",
        "outputId": "794c2de6-9fdf-4714-fa93-bec7c7cfa116"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "SM-CV-LSTM",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}